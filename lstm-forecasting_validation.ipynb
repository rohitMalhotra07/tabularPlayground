{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import dateutil.easter as easter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosAnnealWarmup import CosineAnnealingWarmupRestarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore, Back, Style\n",
    "r_ = Fore.RED\n",
    "b_ = Fore.BLUE\n",
    "c_ = Fore.CYAN\n",
    "g_ = Fore.GREEN\n",
    "y_ = Fore.YELLOW\n",
    "m_ = Fore.MAGENTA\n",
    "sr_ = Style.RESET_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nModel 1 is be multivariate timeseries, each variate represents unique country,store, product\\n\\nWe have 3 countries, 2 stores and 3 products, this means we need to predict 3*2*3 18 values representing each.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### \n",
    "'''\n",
    "Model 1 is be multivariate timeseries, each variate represents unique country,store, product\n",
    "\n",
    "We have 3 countries, 2 stores and 3 products, this means we need to predict 3*2*3 18 values representing each.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id       date  country       store     product  num_sold\n",
       "0       0 2015-01-01  Finland  KaggleMart  Kaggle Mug       329\n",
       "1       1 2015-01-01  Finland  KaggleMart  Kaggle Hat       520"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_train_df = pd.read_csv('./data/train.csv', parse_dates=['date'])\n",
    "# original_test_df = pd.read_csv('./data//test.csv', parse_dates=['date'])\n",
    "gdp_df = pd.read_csv('./data/GDP_data_2015_to_2019_Finland_Norway_Sweden.csv',\n",
    "                    index_col='year')\n",
    "\n",
    "original_train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation Set is 2018 #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_test_df = original_train_df[original_train_df['date'].dt.year == 2018].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19728</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19729</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19730</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19731</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19732</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>1043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id       date  country       store         product  num_sold\n",
       "0   19728 2018-01-01  Finland  KaggleMart      Kaggle Mug       405\n",
       "1   19729 2018-01-01  Finland  KaggleMart      Kaggle Hat       621\n",
       "2   19730 2018-01-01  Finland  KaggleMart  Kaggle Sticker       176\n",
       "3   19731 2018-01-01  Finland  KaggleRama      Kaggle Mug       714\n",
       "4   19732 2018-01-01  Finland  KaggleRama      Kaggle Hat      1043"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_df = original_train_df[original_train_df['date'].dt.year != 2018].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Kaggle Mug', 'Kaggle Hat', 'Kaggle Sticker'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_train_df['product'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def smape_loss(y_true, y_pred):\n",
    "    \"\"\"SMAPE Loss\"\"\"\n",
    "    return np.abs(y_true - y_pred) / (y_true + np.abs(y_pred)) * 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP_Finland</th>\n",
       "      <th>GDP_Norway</th>\n",
       "      <th>GDP_Sweden</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>234.440</td>\n",
       "      <td>385.802</td>\n",
       "      <td>505.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>240.608</td>\n",
       "      <td>368.827</td>\n",
       "      <td>515.655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>255.017</td>\n",
       "      <td>398.394</td>\n",
       "      <td>541.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>275.580</td>\n",
       "      <td>437.000</td>\n",
       "      <td>555.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>268.782</td>\n",
       "      <td>405.510</td>\n",
       "      <td>533.880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      GDP_Finland  GDP_Norway  GDP_Sweden\n",
       "year                                     \n",
       "2015      234.440     385.802     505.104\n",
       "2016      240.608     368.827     515.655\n",
       "2017      255.017     398.394     541.019\n",
       "2018      275.580     437.000     555.455\n",
       "2019      268.782     405.510     533.880"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "def get_gdp(row):\n",
    "    \"\"\"Return the GDP based on row.country and row.date.year\"\"\"\n",
    "    country = 'GDP_' + row.country\n",
    "    return gdp_df.loc[row.date.year, country]\n",
    "\n",
    "le_dict = {feature: LabelEncoder().fit(original_train_df[feature]) for feature in ['country', 'product', 'store']}\n",
    "\n",
    "def engineer(df):\n",
    "    \"\"\"Return a new dataframe with the engineered features\"\"\"\n",
    "    \n",
    "    new_df = pd.DataFrame({'gdp': df.apply(get_gdp, axis=1),\n",
    "                           'dayofyear': df.date.dt.dayofyear,\n",
    "                           'wd4': df.date.dt.weekday == 4, # Friday\n",
    "                           'wd56': df.date.dt.weekday >= 5, # Saturday and Sunday\n",
    "                          })\n",
    "\n",
    "    new_df.loc[(df.date.dt.year != 2016) & (df.date.dt.month >=3), 'dayofyear'] += 1 # fix for leap years\n",
    "    \n",
    "    for feature in ['country', 'product', 'store']:\n",
    "        new_df[feature] = le_dict[feature].transform(df[feature])\n",
    "        \n",
    "    # Easter\n",
    "    easter_date = df.date.apply(lambda date: pd.Timestamp(easter.easter(date.year)))\n",
    "    new_df['days_from_easter'] = (df.date - easter_date).dt.days.clip(-5, 65)\n",
    "    \n",
    "    # Last Sunday of May (Mother's Day)\n",
    "    sun_may_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-5-31')),\n",
    "                                         2016: pd.Timestamp(('2016-5-29')),\n",
    "                                         2017: pd.Timestamp(('2017-5-28')),\n",
    "                                         2018: pd.Timestamp(('2018-5-27')),\n",
    "                                         2019: pd.Timestamp(('2019-5-26'))})\n",
    "    #new_df['days_from_sun_may'] = (df.date - sun_may_date).dt.days.clip(-1, 9)\n",
    "    \n",
    "    # Last Wednesday of June\n",
    "    wed_june_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-06-24')),\n",
    "                                         2016: pd.Timestamp(('2016-06-29')),\n",
    "                                         2017: pd.Timestamp(('2017-06-28')),\n",
    "                                         2018: pd.Timestamp(('2018-06-27')),\n",
    "                                         2019: pd.Timestamp(('2019-06-26'))})\n",
    "    new_df['days_from_wed_jun'] = (df.date - wed_june_date).dt.days.clip(-5, 5)\n",
    "    \n",
    "    # First Sunday of November (second Sunday is Father's Day)\n",
    "    sun_nov_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-11-1')),\n",
    "                                         2016: pd.Timestamp(('2016-11-6')),\n",
    "                                         2017: pd.Timestamp(('2017-11-5')),\n",
    "                                         2018: pd.Timestamp(('2018-11-4')),\n",
    "                                         2019: pd.Timestamp(('2019-11-3'))})\n",
    "    new_df['days_from_sun_nov'] = (df.date - sun_nov_date).dt.days.clip(-1, 9)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "train_df = engineer(original_train_df)\n",
    "train_df['date'] = original_train_df.date # used in GroupKFold\n",
    "train_df['num_sold'] = original_train_df.num_sold.astype(np.float32)\n",
    "train_df['target'] = np.log(train_df['num_sold'] / train_df['gdp'])\n",
    "test_df = engineer(original_test_df)\n",
    "test_df['date'] = original_test_df.date # used in GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gdp</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>wd4</th>\n",
       "      <th>wd56</th>\n",
       "      <th>country</th>\n",
       "      <th>product</th>\n",
       "      <th>store</th>\n",
       "      <th>days_from_easter</th>\n",
       "      <th>days_from_wed_jun</th>\n",
       "      <th>days_from_sun_nov</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>275.580</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>275.580</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>275.580</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275.580</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>275.580</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>555.455</td>\n",
       "      <td>366</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>555.455</td>\n",
       "      <td>366</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>555.455</td>\n",
       "      <td>366</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>555.455</td>\n",
       "      <td>366</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>555.455</td>\n",
       "      <td>366</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6570 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          gdp  dayofyear    wd4   wd56  country  product  store  \\\n",
       "0     275.580          1  False  False        0        1      0   \n",
       "1     275.580          1  False  False        0        0      0   \n",
       "2     275.580          1  False  False        0        2      0   \n",
       "3     275.580          1  False  False        0        1      1   \n",
       "4     275.580          1  False  False        0        0      1   \n",
       "...       ...        ...    ...    ...      ...      ...    ...   \n",
       "6565  555.455        366  False  False        2        0      0   \n",
       "6566  555.455        366  False  False        2        2      0   \n",
       "6567  555.455        366  False  False        2        1      1   \n",
       "6568  555.455        366  False  False        2        0      1   \n",
       "6569  555.455        366  False  False        2        2      1   \n",
       "\n",
       "      days_from_easter  days_from_wed_jun  days_from_sun_nov       date  \n",
       "0                   -5                 -5                 -1 2018-01-01  \n",
       "1                   -5                 -5                 -1 2018-01-01  \n",
       "2                   -5                 -5                 -1 2018-01-01  \n",
       "3                   -5                 -5                 -1 2018-01-01  \n",
       "4                   -5                 -5                 -1 2018-01-01  \n",
       "...                ...                ...                ...        ...  \n",
       "6565                65                  5                  9 2018-12-31  \n",
       "6566                65                  5                  9 2018-12-31  \n",
       "6567                65                  5                  9 2018-12-31  \n",
       "6568                65                  5                  9 2018-12-31  \n",
       "6569                65                  5                  9 2018-12-31  \n",
       "\n",
       "[6570 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_features = ['dayofyear', 'days_from_easter', 'days_from_sun_nov', 'days_from_wed_jun', 'wd4', 'wd56','country','store','product', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gdp</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>wd4</th>\n",
       "      <th>wd56</th>\n",
       "      <th>country</th>\n",
       "      <th>product</th>\n",
       "      <th>store</th>\n",
       "      <th>days_from_easter</th>\n",
       "      <th>days_from_wed_jun</th>\n",
       "      <th>days_from_sun_nov</th>\n",
       "      <th>date</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>234.440</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>329.0</td>\n",
       "      <td>0.338858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>234.440</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.796629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>234.440</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>146.0</td>\n",
       "      <td>-0.473593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>234.440</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>572.0</td>\n",
       "      <td>0.891939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>234.440</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>911.0</td>\n",
       "      <td>1.357343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19723</th>\n",
       "      <td>541.019</td>\n",
       "      <td>366</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>0.650633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19724</th>\n",
       "      <td>541.019</td>\n",
       "      <td>366</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>290.0</td>\n",
       "      <td>-0.623573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19725</th>\n",
       "      <td>541.019</td>\n",
       "      <td>366</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>0.786572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19726</th>\n",
       "      <td>541.019</td>\n",
       "      <td>366</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>1781.0</td>\n",
       "      <td>1.191476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19727</th>\n",
       "      <td>541.019</td>\n",
       "      <td>366</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>530.0</td>\n",
       "      <td>-0.020577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19728 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           gdp  dayofyear    wd4   wd56  country  product  store  \\\n",
       "0      234.440          1  False  False        0        1      0   \n",
       "1      234.440          1  False  False        0        0      0   \n",
       "2      234.440          1  False  False        0        2      0   \n",
       "3      234.440          1  False  False        0        1      1   \n",
       "4      234.440          1  False  False        0        0      1   \n",
       "...        ...        ...    ...    ...      ...      ...    ...   \n",
       "19723  541.019        366  False   True        2        0      0   \n",
       "19724  541.019        366  False   True        2        2      0   \n",
       "19725  541.019        366  False   True        2        1      1   \n",
       "19726  541.019        366  False   True        2        0      1   \n",
       "19727  541.019        366  False   True        2        2      1   \n",
       "\n",
       "       days_from_easter  days_from_wed_jun  days_from_sun_nov       date  \\\n",
       "0                    -5                 -5                 -1 2015-01-01   \n",
       "1                    -5                 -5                 -1 2015-01-01   \n",
       "2                    -5                 -5                 -1 2015-01-01   \n",
       "3                    -5                 -5                 -1 2015-01-01   \n",
       "4                    -5                 -5                 -1 2015-01-01   \n",
       "...                 ...                ...                ...        ...   \n",
       "19723                65                  5                  9 2017-12-31   \n",
       "19724                65                  5                  9 2017-12-31   \n",
       "19725                65                  5                  9 2017-12-31   \n",
       "19726                65                  5                  9 2017-12-31   \n",
       "19727                65                  5                  9 2017-12-31   \n",
       "\n",
       "       num_sold    target  \n",
       "0         329.0  0.338858  \n",
       "1         520.0  0.796629  \n",
       "2         146.0 -0.473593  \n",
       "3         572.0  0.891939  \n",
       "4         911.0  1.357343  \n",
       "...         ...       ...  \n",
       "19723    1037.0  0.650633  \n",
       "19724     290.0 -0.623573  \n",
       "19725    1188.0  0.786572  \n",
       "19726    1781.0  1.191476  \n",
       "19727     530.0 -0.020577  \n",
       "\n",
       "[19728 rows x 13 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grp_df_train = train_df.groupby('date', as_index=False).agg(target = ('target', list),\n",
    "                             dayofyear =('dayofyear', list),\n",
    "                             wd4 =('wd4', list),\n",
    "                             wd56 = ('wd56', list),\n",
    "                             country =('country', list),\n",
    "                             product =('product', list),\n",
    "                             store =('store', list),\n",
    "                             days_from_easter =('days_from_easter', list),\n",
    "                             days_from_wed_jun =('days_from_wed_jun', list),\n",
    "                             days_from_sun_nov =('days_from_sun_nov', list),\n",
    "                            )\n",
    "\n",
    "train_df2 = pd.DataFrame({'date': grp_df_train['date'].values,\n",
    "              'features':grp_df_train.apply(lambda x: np.array([np.array(x[f]) for f in in_features]), axis=1)  \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grp_df_test = test_df.groupby('date', as_index=False).agg(\n",
    "                             dayofyear =('dayofyear', list),\n",
    "                             wd4 =('wd4', list),\n",
    "                             wd56 = ('wd56', list),\n",
    "                             country =('country', list),\n",
    "                             product =('product', list),\n",
    "                             store =('store', list),\n",
    "                             days_from_easter =('days_from_easter', list),\n",
    "                             days_from_wed_jun =('days_from_wed_jun', list),\n",
    "                             days_from_sun_nov =('days_from_sun_nov', list),\n",
    "                            )\n",
    "\n",
    "test_df2 = pd.DataFrame({'date': grp_df_test['date'].values,\n",
    "              'features':grp_df_test.apply(lambda x: np.array([np.array(x[f]) for f in in_features if f!='target']), axis=1)  \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'seq_length' : 60,\n",
    "    'num_epochs' : 200,\n",
    "    'lr' : 0.001,\n",
    "    'input_size' : 180,\n",
    "    'hidden_size' : 360,\n",
    "    'num_layers' : 2,\n",
    "    'num_classes' :18, ## This is  output dimension\n",
    "    'train_shuffle': True,\n",
    "    'val_shuffle': True,\n",
    "    'batch_size' : 30,\n",
    "    'best_model_name' : 'lstm_tsp_validation_mlp_head_bn_last_hidden_1.bin',\n",
    "    'bidirectional' : False,\n",
    "    'only_last_hidden': False\n",
    "}\n",
    "# config_lr = {'T_max':20,\n",
    "#              'eta_min':0\n",
    "#             }\n",
    "# config_lr = { 'first_cycle_steps':50,\n",
    "#               'cycle_mult':1.0,\n",
    "#                'max_lr':0.1,\n",
    "#               'min_lr':0.001,\n",
    "#               'warmup_steps':5,\n",
    "#               'gamma':1.0\n",
    "#             }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sequences ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(data, seq_length):\n",
    "        x = []\n",
    "        y = []\n",
    "\n",
    "        for i in range(len(data)-seq_length-1):\n",
    "            _x = data[i:(i+seq_length),:].transpose(0,2,1).reshape(seq_length,-1)\n",
    "            _y = data[i+seq_length,-1]\n",
    "            x.append(_x)\n",
    "            y.append(_y)\n",
    "\n",
    "        return np.array(x),np.array(y)\n",
    "    \n",
    "def make_sequences(df,seq_length):\n",
    "    data = np.rollaxis(np.dstack(df['features'].values.tolist()),-1)\n",
    "    print('Data Shape', data.shape)\n",
    "    \n",
    "    x, y = sliding_windows(data, seq_length)\n",
    "\n",
    "    print('X,y shapes', x.shape,y.shape)\n",
    "    \n",
    "    return x,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape (1096, 10, 18)\n",
      "X,y shapes (1035, 60, 180) (1035, 18)\n"
     ]
    }
   ],
   "source": [
    "X,y = make_sequences(train_df2,config['seq_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TPSDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x,y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        \"\"\"\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = [torch.Tensor(self.x[idx]), torch.Tensor(self.y[idx])]\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = config['num_epochs']\n",
    "lr = config['lr']\n",
    "input_size = config['input_size']\n",
    "hidden_size = config['hidden_size']\n",
    "num_layers = config['num_layers']\n",
    "num_classes = config['num_classes']\n",
    "seq_length = config['seq_length']\n",
    "bidirectional = config['bidirectional']\n",
    "only_last_hidden = config['only_last_hidden']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "360//32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTMTpsModel(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers,seq_length):\n",
    "        super(LSTMTpsModel, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True,bidirectional=bidirectional)\n",
    "        \n",
    "        if bidirectional:\n",
    "            m=2\n",
    "        else:\n",
    "            m=1\n",
    "        \n",
    "        if only_last_hidden:\n",
    "            input_dim = hidden_size*m\n",
    "        else:\n",
    "            input_dim = self.seq_length*hidden_size*m\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Linear(input_dim, input_dim//8),\n",
    "                                nn.BatchNorm1d(num_features=input_dim//8),\n",
    "                                # nn.Dropout(0.2),\n",
    "                                nn.ReLU(),\n",
    "                                \n",
    "                                nn.Linear(input_dim//8, input_dim//16),\n",
    "                                nn.BatchNorm1d(num_features=input_dim//16),\n",
    "                                # nn.Dropout(0.2),\n",
    "                                nn.ReLU(),\n",
    "                                \n",
    "                                nn.Linear(input_dim//16, input_dim//32),\n",
    "                                nn.BatchNorm1d(num_features=input_dim//32),\n",
    "                                # nn.Dropout(0.2),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(input_dim//32, self.num_classes)\n",
    "                                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Propagate input through LSTM\n",
    "        h_out, (_, _) = self.lstm(x)\n",
    "        if only_last_hidden:\n",
    "            h_out = h_out[:,-1:,:]\n",
    "        h_out = h_out.flatten(start_dim=1)\n",
    "        \n",
    "        out = self.fc(h_out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model,train_dl,val_dl):\n",
    "    def evaluate(model,valid_loader):\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        rec_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for i, inputs in enumerate(valid_loader):\n",
    "                dataX = inputs[0]\n",
    "                dataY = inputs[1]\n",
    "                outputs = model(dataX)\n",
    "                loss = criterion(outputs, dataY)\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "        valid_loss /= len(valid_loader)\n",
    "        return valid_loss\n",
    "    \n",
    "    def train_and_evaluate_loop(train_loader,model,optimizer,criterion,epoch,lr_scheduler=None,valid_loader=None, best_loss=99999):\n",
    "        train_loss = 0\n",
    "        for i, inputs in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            model.train()\n",
    "            \n",
    "            dataX = inputs[0]\n",
    "            dataY = inputs[1]\n",
    "            outputs = model(dataX)\n",
    "            loss = criterion(outputs, dataY)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            if lr_scheduler:\n",
    "                lr_scheduler.step()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        if valid_loader:\n",
    "            valid_loss = evaluate(model,valid_loader) \n",
    "            print(f\"Epoch:{epoch} |Train Loss:{train_loss}|Valid Loss:{valid_loss}\")\n",
    "            if valid_loss <= best_loss:\n",
    "                print(f\"{g_}Loss Decreased from {best_loss} to {valid_loss}{sr_}\")\n",
    "\n",
    "                best_loss = valid_loss\n",
    "                torch.save(model.state_dict(), config['best_model_name'])\n",
    "        else:\n",
    "            print(f\"Epoch:{epoch} |Train Loss:{train_loss}\")\n",
    "            \n",
    "                    \n",
    "        return best_loss\n",
    "    \n",
    "    accelerator = Accelerator()\n",
    "    print(f\"{accelerator.device} is used\")\n",
    "\n",
    "    \n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(),lr=config['lr'],amsgrad=False)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    # lr_scheduler = CosineAnnealingWarmupRestarts(optimizer, **config_lr)\n",
    "    # lr_scheduler =  torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, **config_lr)\n",
    "    lr_scheduler = None\n",
    "\n",
    "    model,train_dl,val_dl,optimizer,lr_scheduler,criterion = accelerator.prepare(model,train_dl,val_dl,optimizer,lr_scheduler,criterion)\n",
    "\n",
    "    best_loss = 9999999\n",
    "    start_time = time.time()\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        print(f\"Epoch Started:{epoch}\")\n",
    "        best_loss = train_and_evaluate_loop(train_dl,model,optimizer,criterion,epoch,lr_scheduler,valid_loader=val_dl, best_loss=best_loss)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"{m_}Time taken by epoch {epoch} is {end_time-start_time:.2f}s{sr_}\")\n",
    "        start_time = end_time\n",
    "        \n",
    "    return best_loss, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMTpsModel(num_classes, input_size, hidden_size, num_layers,seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(TPSDataset(X_train, y_train), batch_size=config['batch_size'], shuffle=config['train_shuffle'], num_workers=2)\n",
    "val_dl = DataLoader(TPSDataset(X_val, y_val), batch_size=config['batch_size'], shuffle=config['train_shuffle'], num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n",
      "Epoch Started:0\n",
      "Epoch:0 |Train Loss:0.5968353865402085|Valid Loss:0.4756225177219936\n",
      "\u001b[32mLoss Decreased from 9999999 to 0.4756225177219936\u001b[0m\n",
      "\u001b[35mTime taken by epoch 0 is 0.78s\u001b[0m\n",
      "Epoch Started:1\n",
      "Epoch:1 |Train Loss:0.4250317130770002|Valid Loss:0.3938689487321036\n",
      "\u001b[32mLoss Decreased from 0.4756225177219936 to 0.3938689487321036\u001b[0m\n",
      "\u001b[35mTime taken by epoch 1 is 0.61s\u001b[0m\n",
      "Epoch Started:2\n",
      "Epoch:2 |Train Loss:0.31433527171611786|Valid Loss:0.2533967984574182\n",
      "\u001b[32mLoss Decreased from 0.3938689487321036 to 0.2533967984574182\u001b[0m\n",
      "\u001b[35mTime taken by epoch 2 is 0.53s\u001b[0m\n",
      "Epoch Started:3\n",
      "Epoch:3 |Train Loss:0.22841437320624078|Valid Loss:0.19995904181684768\n",
      "\u001b[32mLoss Decreased from 0.2533967984574182 to 0.19995904181684768\u001b[0m\n",
      "\u001b[35mTime taken by epoch 3 is 0.62s\u001b[0m\n",
      "Epoch Started:4\n",
      "Epoch:4 |Train Loss:0.16647249087691307|Valid Loss:0.14151444605418614\n",
      "\u001b[32mLoss Decreased from 0.19995904181684768 to 0.14151444605418614\u001b[0m\n",
      "\u001b[35mTime taken by epoch 4 is 0.72s\u001b[0m\n",
      "Epoch Started:5\n",
      "Epoch:5 |Train Loss:0.11803593912294932|Valid Loss:0.11632949220282691\n",
      "\u001b[32mLoss Decreased from 0.14151444605418614 to 0.11632949220282691\u001b[0m\n",
      "\u001b[35mTime taken by epoch 5 is 0.62s\u001b[0m\n",
      "Epoch Started:6\n",
      "Epoch:6 |Train Loss:0.08741404714861087|Valid Loss:0.08351135892527443\n",
      "\u001b[32mLoss Decreased from 0.11632949220282691 to 0.08351135892527443\u001b[0m\n",
      "\u001b[35mTime taken by epoch 6 is 0.59s\u001b[0m\n",
      "Epoch Started:7\n",
      "Epoch:7 |Train Loss:0.06527499402207988|Valid Loss:0.06478559172579221\n",
      "\u001b[32mLoss Decreased from 0.08351135892527443 to 0.06478559172579221\u001b[0m\n",
      "\u001b[35mTime taken by epoch 7 is 0.62s\u001b[0m\n",
      "Epoch Started:8\n",
      "Epoch:8 |Train Loss:0.05165754737598555|Valid Loss:0.046383707118885856\n",
      "\u001b[32mLoss Decreased from 0.06478559172579221 to 0.046383707118885856\u001b[0m\n",
      "\u001b[35mTime taken by epoch 8 is 0.63s\u001b[0m\n",
      "Epoch Started:9\n",
      "Epoch:9 |Train Loss:0.048336334859154055|Valid Loss:0.03870025756103652\n",
      "\u001b[32mLoss Decreased from 0.046383707118885856 to 0.03870025756103652\u001b[0m\n",
      "\u001b[35mTime taken by epoch 9 is 0.81s\u001b[0m\n",
      "Epoch Started:10\n",
      "Epoch:10 |Train Loss:0.04148566589823791|Valid Loss:0.03948812319764069\n",
      "\u001b[35mTime taken by epoch 10 is 0.77s\u001b[0m\n",
      "Epoch Started:11\n",
      "Epoch:11 |Train Loss:0.03816232717196856|Valid Loss:0.10097413722957883\n",
      "\u001b[35mTime taken by epoch 11 is 0.73s\u001b[0m\n",
      "Epoch Started:12\n",
      "Epoch:12 |Train Loss:0.03786618315747806|Valid Loss:0.04529308261615889\n",
      "\u001b[35mTime taken by epoch 12 is 0.70s\u001b[0m\n",
      "Epoch Started:13\n",
      "Epoch:13 |Train Loss:0.035793183504470756|Valid Loss:0.06022091316325324\n",
      "\u001b[35mTime taken by epoch 13 is 0.50s\u001b[0m\n",
      "Epoch Started:14\n",
      "Epoch:14 |Train Loss:0.03594227846977966|Valid Loss:0.04252793959208897\n",
      "\u001b[35mTime taken by epoch 14 is 0.55s\u001b[0m\n",
      "Epoch Started:15\n",
      "Epoch:15 |Train Loss:0.039836392272263765|Valid Loss:0.0456641289804663\n",
      "\u001b[35mTime taken by epoch 15 is 0.57s\u001b[0m\n",
      "Epoch Started:16\n",
      "Epoch:16 |Train Loss:0.03639629263696926|Valid Loss:0.029927429610065052\n",
      "\u001b[32mLoss Decreased from 0.03870025756103652 to 0.029927429610065052\u001b[0m\n",
      "\u001b[35mTime taken by epoch 16 is 0.57s\u001b[0m\n",
      "Epoch Started:17\n",
      "Epoch:17 |Train Loss:0.03942523238116077|Valid Loss:0.04335887464029448\n",
      "\u001b[35mTime taken by epoch 17 is 0.52s\u001b[0m\n",
      "Epoch Started:18\n",
      "Epoch:18 |Train Loss:0.0346862825431994|Valid Loss:0.027471486212951795\n",
      "\u001b[32mLoss Decreased from 0.029927429610065052 to 0.027471486212951795\u001b[0m\n",
      "\u001b[35mTime taken by epoch 18 is 0.60s\u001b[0m\n",
      "Epoch Started:19\n",
      "Epoch:19 |Train Loss:0.03456271020695567|Valid Loss:0.0297111091869218\n",
      "\u001b[35mTime taken by epoch 19 is 0.59s\u001b[0m\n",
      "Epoch Started:20\n",
      "Epoch:20 |Train Loss:0.035530318572585075|Valid Loss:0.02746218096997057\n",
      "\u001b[32mLoss Decreased from 0.027471486212951795 to 0.02746218096997057\u001b[0m\n",
      "\u001b[35mTime taken by epoch 20 is 0.64s\u001b[0m\n",
      "Epoch Started:21\n",
      "Epoch:21 |Train Loss:0.0346661106949406|Valid Loss:0.027765671589544842\n",
      "\u001b[35mTime taken by epoch 21 is 0.76s\u001b[0m\n",
      "Epoch Started:22\n",
      "Epoch:22 |Train Loss:0.032282211551708836|Valid Loss:0.0313189471406596\n",
      "\u001b[35mTime taken by epoch 22 is 0.74s\u001b[0m\n",
      "Epoch Started:23\n",
      "Epoch:23 |Train Loss:0.031600420496293476|Valid Loss:0.026039813246045793\n",
      "\u001b[32mLoss Decreased from 0.02746218096997057 to 0.026039813246045793\u001b[0m\n",
      "\u001b[35mTime taken by epoch 23 is 0.57s\u001b[0m\n",
      "Epoch Started:24\n",
      "Epoch:24 |Train Loss:0.030726535046207055|Valid Loss:0.025018892916185514\n",
      "\u001b[32mLoss Decreased from 0.026039813246045793 to 0.025018892916185514\u001b[0m\n",
      "\u001b[35mTime taken by epoch 24 is 0.56s\u001b[0m\n",
      "Epoch Started:25\n",
      "Epoch:25 |Train Loss:0.031518411955663135|Valid Loss:0.027729303975190436\n",
      "\u001b[35mTime taken by epoch 25 is 0.56s\u001b[0m\n",
      "Epoch Started:26\n",
      "Epoch:26 |Train Loss:0.03042952560021409|Valid Loss:0.02496747486293316\n",
      "\u001b[32mLoss Decreased from 0.025018892916185514 to 0.02496747486293316\u001b[0m\n",
      "\u001b[35mTime taken by epoch 26 is 0.63s\u001b[0m\n",
      "Epoch Started:27\n",
      "Epoch:27 |Train Loss:0.032121155344481976|Valid Loss:0.02803769734288965\n",
      "\u001b[35mTime taken by epoch 27 is 0.57s\u001b[0m\n",
      "Epoch Started:28\n",
      "Epoch:28 |Train Loss:0.03124256312314953|Valid Loss:0.02797786279448441\n",
      "\u001b[35mTime taken by epoch 28 is 0.91s\u001b[0m\n",
      "Epoch Started:29\n",
      "Epoch:29 |Train Loss:0.030238132724272355|Valid Loss:0.02760570709194456\n",
      "\u001b[35mTime taken by epoch 29 is 0.54s\u001b[0m\n",
      "Epoch Started:30\n",
      "Epoch:30 |Train Loss:0.029562287032604218|Valid Loss:0.023092406668833325\n",
      "\u001b[32mLoss Decreased from 0.02496747486293316 to 0.023092406668833325\u001b[0m\n",
      "\u001b[35mTime taken by epoch 30 is 0.53s\u001b[0m\n",
      "Epoch Started:31\n",
      "Epoch:31 |Train Loss:0.03019083953196449|Valid Loss:0.024798215233853886\n",
      "\u001b[35mTime taken by epoch 31 is 0.63s\u001b[0m\n",
      "Epoch Started:32\n",
      "Epoch:32 |Train Loss:0.03029741732669728|Valid Loss:0.03598165059728282\n",
      "\u001b[35mTime taken by epoch 32 is 0.56s\u001b[0m\n",
      "Epoch Started:33\n",
      "Epoch:33 |Train Loss:0.0317404451447406|Valid Loss:0.041703405656984875\n",
      "\u001b[35mTime taken by epoch 33 is 0.69s\u001b[0m\n",
      "Epoch Started:34\n",
      "Epoch:34 |Train Loss:0.04855959922341364|Valid Loss:0.08977405514035906\n",
      "\u001b[35mTime taken by epoch 34 is 0.53s\u001b[0m\n",
      "Epoch Started:35\n",
      "Epoch:35 |Train Loss:0.037418865133076906|Valid Loss:0.08488084482295173\n",
      "\u001b[35mTime taken by epoch 35 is 0.56s\u001b[0m\n",
      "Epoch Started:36\n",
      "Epoch:36 |Train Loss:0.04672896808811596|Valid Loss:0.2676652797630855\n",
      "\u001b[35mTime taken by epoch 36 is 0.84s\u001b[0m\n",
      "Epoch Started:37\n",
      "Epoch:37 |Train Loss:0.038059154858014414|Valid Loss:0.05950065276452473\n",
      "\u001b[35mTime taken by epoch 37 is 0.55s\u001b[0m\n",
      "Epoch Started:38\n",
      "Epoch:38 |Train Loss:0.035086067859083414|Valid Loss:0.04566607145326478\n",
      "\u001b[35mTime taken by epoch 38 is 0.56s\u001b[0m\n",
      "Epoch Started:39\n",
      "Epoch:39 |Train Loss:0.03369715982781989|Valid Loss:0.07654330560139247\n",
      "\u001b[35mTime taken by epoch 39 is 0.61s\u001b[0m\n",
      "Epoch Started:40\n",
      "Epoch:40 |Train Loss:0.037892705095665793|Valid Loss:0.04066331897463117\n",
      "\u001b[35mTime taken by epoch 40 is 0.53s\u001b[0m\n",
      "Epoch Started:41\n",
      "Epoch:41 |Train Loss:0.033051844752792804|Valid Loss:0.04206887206860951\n",
      "\u001b[35mTime taken by epoch 41 is 0.76s\u001b[0m\n",
      "Epoch Started:42\n",
      "Epoch:42 |Train Loss:0.03264247506324734|Valid Loss:0.024683136492967606\n",
      "\u001b[35mTime taken by epoch 42 is 0.56s\u001b[0m\n",
      "Epoch Started:43\n",
      "Epoch:43 |Train Loss:0.0313205461882587|Valid Loss:0.027533219861132757\n",
      "\u001b[35mTime taken by epoch 43 is 0.58s\u001b[0m\n",
      "Epoch Started:44\n",
      "Epoch:44 |Train Loss:0.03015843067052109|Valid Loss:0.03540160586791379\n",
      "\u001b[35mTime taken by epoch 44 is 0.56s\u001b[0m\n",
      "Epoch Started:45\n",
      "Epoch:45 |Train Loss:0.030482594422729953|Valid Loss:0.030121659061738422\n",
      "\u001b[35mTime taken by epoch 45 is 0.62s\u001b[0m\n",
      "Epoch Started:46\n",
      "Epoch:46 |Train Loss:0.030029044752674445|Valid Loss:0.05607915722898075\n",
      "\u001b[35mTime taken by epoch 46 is 0.62s\u001b[0m\n",
      "Epoch Started:47\n",
      "Epoch:47 |Train Loss:0.03047212532588414|Valid Loss:0.02466954104602337\n",
      "\u001b[35mTime taken by epoch 47 is 0.58s\u001b[0m\n",
      "Epoch Started:48\n",
      "Epoch:48 |Train Loss:0.03088882179664714|Valid Loss:0.0398688656943185\n",
      "\u001b[35mTime taken by epoch 48 is 0.62s\u001b[0m\n",
      "Epoch Started:49\n",
      "Epoch:49 |Train Loss:0.03136659586536033|Valid Loss:0.03237916475960186\n",
      "\u001b[35mTime taken by epoch 49 is 0.59s\u001b[0m\n",
      "Epoch Started:50\n",
      "Epoch:50 |Train Loss:0.026955566867919906|Valid Loss:0.03210512309202126\n",
      "\u001b[35mTime taken by epoch 50 is 0.93s\u001b[0m\n",
      "Epoch Started:51\n",
      "Epoch:51 |Train Loss:0.030185195251501033|Valid Loss:0.03417737941656794\n",
      "\u001b[35mTime taken by epoch 51 is 0.58s\u001b[0m\n",
      "Epoch Started:52\n",
      "Epoch:52 |Train Loss:0.029573506708922132|Valid Loss:0.026593928624476706\n",
      "\u001b[35mTime taken by epoch 52 is 0.63s\u001b[0m\n",
      "Epoch Started:53\n",
      "Epoch:53 |Train Loss:0.029680051940626333|Valid Loss:0.05235399359038898\n",
      "\u001b[35mTime taken by epoch 53 is 0.62s\u001b[0m\n",
      "Epoch Started:54\n",
      "Epoch:54 |Train Loss:0.030353784394849623|Valid Loss:0.0366363948477166\n",
      "\u001b[35mTime taken by epoch 54 is 0.68s\u001b[0m\n",
      "Epoch Started:55\n",
      "Epoch:55 |Train Loss:0.030207872490531633|Valid Loss:0.03335084899195603\n",
      "\u001b[35mTime taken by epoch 55 is 0.64s\u001b[0m\n",
      "Epoch Started:56\n",
      "Epoch:56 |Train Loss:0.029566935962066054|Valid Loss:0.026466484181582928\n",
      "\u001b[35mTime taken by epoch 56 is 0.66s\u001b[0m\n",
      "Epoch Started:57\n",
      "Epoch:57 |Train Loss:0.02903880990509476|Valid Loss:0.13538113875048502\n",
      "\u001b[35mTime taken by epoch 57 is 0.57s\u001b[0m\n",
      "Epoch Started:58\n",
      "Epoch:58 |Train Loss:0.029715164564549923|Valid Loss:0.06011650658079556\n",
      "\u001b[35mTime taken by epoch 58 is 0.64s\u001b[0m\n",
      "Epoch Started:59\n",
      "Epoch:59 |Train Loss:0.02979484892317227|Valid Loss:0.028571047421012605\n",
      "\u001b[35mTime taken by epoch 59 is 0.61s\u001b[0m\n",
      "Epoch Started:60\n",
      "Epoch:60 |Train Loss:0.027610472669558867|Valid Loss:0.024312250715281283\n",
      "\u001b[35mTime taken by epoch 60 is 0.71s\u001b[0m\n",
      "Epoch Started:61\n",
      "Epoch:61 |Train Loss:0.028070404161033884|Valid Loss:0.02356825289981706\n",
      "\u001b[35mTime taken by epoch 61 is 0.69s\u001b[0m\n",
      "Epoch Started:62\n",
      "Epoch:62 |Train Loss:0.0279488752130419|Valid Loss:0.029538611748388836\n",
      "\u001b[35mTime taken by epoch 62 is 0.72s\u001b[0m\n",
      "Epoch Started:63\n",
      "Epoch:63 |Train Loss:0.027225765898557647|Valid Loss:0.02465101278253964\n",
      "\u001b[35mTime taken by epoch 63 is 0.64s\u001b[0m\n",
      "Epoch Started:64\n",
      "Epoch:64 |Train Loss:0.028668111822168742|Valid Loss:0.02677946910262108\n",
      "\u001b[35mTime taken by epoch 64 is 0.60s\u001b[0m\n",
      "Epoch Started:65\n",
      "Epoch:65 |Train Loss:0.0275339069776237|Valid Loss:0.02464429714850017\n",
      "\u001b[35mTime taken by epoch 65 is 0.59s\u001b[0m\n",
      "Epoch Started:66\n",
      "Epoch:66 |Train Loss:0.028018695136000003|Valid Loss:0.02372161378817899\n",
      "\u001b[35mTime taken by epoch 66 is 0.95s\u001b[0m\n",
      "Epoch Started:67\n",
      "Epoch:67 |Train Loss:0.0275740031751671|Valid Loss:0.02169069687702826\n",
      "\u001b[32mLoss Decreased from 0.023092406668833325 to 0.02169069687702826\u001b[0m\n",
      "\u001b[35mTime taken by epoch 67 is 0.63s\u001b[0m\n",
      "Epoch Started:68\n",
      "Epoch:68 |Train Loss:0.026990224973165562|Valid Loss:0.0334610790014267\n",
      "\u001b[35mTime taken by epoch 68 is 0.52s\u001b[0m\n",
      "Epoch Started:69\n",
      "Epoch:69 |Train Loss:0.026435345211731538|Valid Loss:0.02194337174296379\n",
      "\u001b[35mTime taken by epoch 69 is 0.55s\u001b[0m\n",
      "Epoch Started:70\n",
      "Epoch:70 |Train Loss:0.027606335801205466|Valid Loss:0.028957609087228775\n",
      "\u001b[35mTime taken by epoch 70 is 0.57s\u001b[0m\n",
      "Epoch Started:71\n",
      "Epoch:71 |Train Loss:0.027169075794517994|Valid Loss:0.023531599236386164\n",
      "\u001b[35mTime taken by epoch 71 is 0.52s\u001b[0m\n",
      "Epoch Started:72\n",
      "Epoch:72 |Train Loss:0.027291171651865755|Valid Loss:0.02216396534017154\n",
      "\u001b[35mTime taken by epoch 72 is 0.53s\u001b[0m\n",
      "Epoch Started:73\n",
      "Epoch:73 |Train Loss:0.026694896930296506|Valid Loss:0.02266153773026807\n",
      "\u001b[35mTime taken by epoch 73 is 0.51s\u001b[0m\n",
      "Epoch Started:74\n",
      "Epoch:74 |Train Loss:0.026979170872696807|Valid Loss:0.02259309310466051\n",
      "\u001b[35mTime taken by epoch 74 is 0.69s\u001b[0m\n",
      "Epoch Started:75\n",
      "Epoch:75 |Train Loss:0.026627580103065287|Valid Loss:0.02229022660425731\n",
      "\u001b[35mTime taken by epoch 75 is 0.60s\u001b[0m\n",
      "Epoch Started:76\n",
      "Epoch:76 |Train Loss:0.02745605991887195|Valid Loss:0.030736376398376057\n",
      "\u001b[35mTime taken by epoch 76 is 0.52s\u001b[0m\n",
      "Epoch Started:77\n",
      "Epoch:77 |Train Loss:0.02697935058469219|Valid Loss:0.024326358921825886\n",
      "\u001b[35mTime taken by epoch 77 is 0.56s\u001b[0m\n",
      "Epoch Started:78\n",
      "Epoch:78 |Train Loss:0.026742243274514164|Valid Loss:0.024316886173827306\n",
      "\u001b[35mTime taken by epoch 78 is 0.53s\u001b[0m\n",
      "Epoch Started:79\n",
      "Epoch:79 |Train Loss:0.0271354682211365|Valid Loss:0.023638150920825347\n",
      "\u001b[35mTime taken by epoch 79 is 0.63s\u001b[0m\n",
      "Epoch Started:80\n",
      "Epoch:80 |Train Loss:0.026722966992695416|Valid Loss:0.025219832680055072\n",
      "\u001b[35mTime taken by epoch 80 is 0.58s\u001b[0m\n",
      "Epoch Started:81\n",
      "Epoch:81 |Train Loss:0.026569926512560675|Valid Loss:0.02490793035498687\n",
      "\u001b[35mTime taken by epoch 81 is 0.60s\u001b[0m\n",
      "Epoch Started:82\n",
      "Epoch:82 |Train Loss:0.026733752073986188|Valid Loss:0.025138292195541517\n",
      "\u001b[35mTime taken by epoch 82 is 0.62s\u001b[0m\n",
      "Epoch Started:83\n",
      "Epoch:83 |Train Loss:0.02672922148901437|Valid Loss:0.022904988511332443\n",
      "\u001b[35mTime taken by epoch 83 is 0.52s\u001b[0m\n",
      "Epoch Started:84\n",
      "Epoch:84 |Train Loss:0.026642419397830963|Valid Loss:0.024379926334534372\n",
      "\u001b[35mTime taken by epoch 84 is 0.60s\u001b[0m\n",
      "Epoch Started:85\n",
      "Epoch:85 |Train Loss:0.027297034793134247|Valid Loss:0.022277005282895907\n",
      "\u001b[35mTime taken by epoch 85 is 0.58s\u001b[0m\n",
      "Epoch Started:86\n",
      "Epoch:86 |Train Loss:0.026540975784882903|Valid Loss:0.02235859472836767\n",
      "\u001b[35mTime taken by epoch 86 is 0.54s\u001b[0m\n",
      "Epoch Started:87\n",
      "Epoch:87 |Train Loss:0.026769392724548067|Valid Loss:0.022572900168597698\n",
      "\u001b[35mTime taken by epoch 87 is 0.58s\u001b[0m\n",
      "Epoch Started:88\n",
      "Epoch:88 |Train Loss:0.0271247398174767|Valid Loss:0.023184323417288915\n",
      "\u001b[35mTime taken by epoch 88 is 0.61s\u001b[0m\n",
      "Epoch Started:89\n",
      "Epoch:89 |Train Loss:0.02769939524919859|Valid Loss:0.025373260357550213\n",
      "\u001b[35mTime taken by epoch 89 is 0.60s\u001b[0m\n",
      "Epoch Started:90\n",
      "Epoch:90 |Train Loss:0.027205820328422954|Valid Loss:0.022665420014943396\n",
      "\u001b[35mTime taken by epoch 90 is 0.52s\u001b[0m\n",
      "Epoch Started:91\n",
      "Epoch:91 |Train Loss:0.02746337216480502|Valid Loss:0.022020846605300903\n",
      "\u001b[35mTime taken by epoch 91 is 0.52s\u001b[0m\n",
      "Epoch Started:92\n",
      "Epoch:92 |Train Loss:0.0268069370649755|Valid Loss:0.02541274470942361\n",
      "\u001b[35mTime taken by epoch 92 is 0.59s\u001b[0m\n",
      "Epoch Started:93\n",
      "Epoch:93 |Train Loss:0.02636589921478714|Valid Loss:0.036181998039994924\n",
      "\u001b[35mTime taken by epoch 93 is 0.54s\u001b[0m\n",
      "Epoch Started:94\n",
      "Epoch:94 |Train Loss:0.027473028982058167|Valid Loss:0.021537514935646738\n",
      "\u001b[32mLoss Decreased from 0.02169069687702826 to 0.021537514935646738\u001b[0m\n",
      "\u001b[35mTime taken by epoch 94 is 0.53s\u001b[0m\n",
      "Epoch Started:95\n",
      "Epoch:95 |Train Loss:0.02791737429132419|Valid Loss:0.023675708898476193\n",
      "\u001b[35mTime taken by epoch 95 is 0.52s\u001b[0m\n",
      "Epoch Started:96\n",
      "Epoch:96 |Train Loss:0.028306046700371162|Valid Loss:0.12841076297419413\n",
      "\u001b[35mTime taken by epoch 96 is 0.52s\u001b[0m\n",
      "Epoch Started:97\n",
      "Epoch:97 |Train Loss:0.027823604177683592|Valid Loss:0.02865391144795077\n",
      "\u001b[35mTime taken by epoch 97 is 0.53s\u001b[0m\n",
      "Epoch Started:98\n",
      "Epoch:98 |Train Loss:0.026875072258657644|Valid Loss:0.02459290051566703\n",
      "\u001b[35mTime taken by epoch 98 is 0.59s\u001b[0m\n",
      "Epoch Started:99\n",
      "Epoch:99 |Train Loss:0.026737334273223366|Valid Loss:0.023509608581662178\n",
      "\u001b[35mTime taken by epoch 99 is 0.60s\u001b[0m\n",
      "Epoch Started:100\n",
      "Epoch:100 |Train Loss:0.026562783368197933|Valid Loss:0.026610887476376126\n",
      "\u001b[35mTime taken by epoch 100 is 0.54s\u001b[0m\n",
      "Epoch Started:101\n",
      "Epoch:101 |Train Loss:0.027075766153367504|Valid Loss:0.03068900667130947\n",
      "\u001b[35mTime taken by epoch 101 is 0.57s\u001b[0m\n",
      "Epoch Started:102\n",
      "Epoch:102 |Train Loss:0.027113285813746706|Valid Loss:0.022050261896635805\n",
      "\u001b[35mTime taken by epoch 102 is 0.57s\u001b[0m\n",
      "Epoch Started:103\n",
      "Epoch:103 |Train Loss:0.02710856683552265|Valid Loss:0.02423295857650893\n",
      "\u001b[35mTime taken by epoch 103 is 0.52s\u001b[0m\n",
      "Epoch Started:104\n",
      "Epoch:104 |Train Loss:0.027621841557057842|Valid Loss:0.024068693098212992\n",
      "\u001b[35mTime taken by epoch 104 is 0.53s\u001b[0m\n",
      "Epoch Started:105\n",
      "Epoch:105 |Train Loss:0.026242796098813415|Valid Loss:0.023170603971396173\n",
      "\u001b[35mTime taken by epoch 105 is 0.59s\u001b[0m\n",
      "Epoch Started:106\n",
      "Epoch:106 |Train Loss:0.027161067118868232|Valid Loss:0.031783202929156165\n",
      "\u001b[35mTime taken by epoch 106 is 0.50s\u001b[0m\n",
      "Epoch Started:107\n",
      "Epoch:107 |Train Loss:0.02750385519383209|Valid Loss:0.023675506934523582\n",
      "\u001b[35mTime taken by epoch 107 is 0.57s\u001b[0m\n",
      "Epoch Started:108\n",
      "Epoch:108 |Train Loss:0.02711909866359617|Valid Loss:0.022307271270879676\n",
      "\u001b[35mTime taken by epoch 108 is 0.55s\u001b[0m\n",
      "Epoch Started:109\n",
      "Epoch:109 |Train Loss:0.028252033982425928|Valid Loss:0.034848736599087715\n",
      "\u001b[35mTime taken by epoch 109 is 0.86s\u001b[0m\n",
      "Epoch Started:110\n",
      "Epoch:110 |Train Loss:0.026805852373529757|Valid Loss:0.026186298578977585\n",
      "\u001b[35mTime taken by epoch 110 is 0.60s\u001b[0m\n",
      "Epoch Started:111\n",
      "Epoch:111 |Train Loss:0.027166051025103246|Valid Loss:0.026831903361848423\n",
      "\u001b[35mTime taken by epoch 111 is 0.54s\u001b[0m\n",
      "Epoch Started:112\n",
      "Epoch:112 |Train Loss:0.026196443675351993|Valid Loss:0.022774542814918926\n",
      "\u001b[35mTime taken by epoch 112 is 0.49s\u001b[0m\n",
      "Epoch Started:113\n",
      "Epoch:113 |Train Loss:0.02620238295224096|Valid Loss:0.024382844301206723\n",
      "\u001b[35mTime taken by epoch 113 is 0.50s\u001b[0m\n",
      "Epoch Started:114\n",
      "Epoch:114 |Train Loss:0.02579402118655188|Valid Loss:0.024606145652277128\n",
      "\u001b[35mTime taken by epoch 114 is 0.50s\u001b[0m\n",
      "Epoch Started:115\n",
      "Epoch:115 |Train Loss:0.026836223767272065|Valid Loss:0.030700079298445156\n",
      "\u001b[35mTime taken by epoch 115 is 0.65s\u001b[0m\n",
      "Epoch Started:116\n",
      "Epoch:116 |Train Loss:0.027518687403893898|Valid Loss:0.021693995355495384\n",
      "\u001b[35mTime taken by epoch 116 is 0.61s\u001b[0m\n",
      "Epoch Started:117\n",
      "Epoch:117 |Train Loss:0.02677937414097999|Valid Loss:0.023321650257068022\n",
      "\u001b[35mTime taken by epoch 117 is 0.67s\u001b[0m\n",
      "Epoch Started:118\n",
      "Epoch:118 |Train Loss:0.026149913236232742|Valid Loss:0.025602087112409726\n",
      "\u001b[35mTime taken by epoch 118 is 0.62s\u001b[0m\n",
      "Epoch Started:119\n",
      "Epoch:119 |Train Loss:0.025637363449537327|Valid Loss:0.04629471844860485\n",
      "\u001b[35mTime taken by epoch 119 is 0.63s\u001b[0m\n",
      "Epoch Started:120\n",
      "Epoch:120 |Train Loss:0.025723172251933386|Valid Loss:0.02665822846548898\n",
      "\u001b[35mTime taken by epoch 120 is 0.92s\u001b[0m\n",
      "Epoch Started:121\n",
      "Epoch:121 |Train Loss:0.02647076061527644|Valid Loss:0.03520038351416588\n",
      "\u001b[35mTime taken by epoch 121 is 0.65s\u001b[0m\n",
      "Epoch Started:122\n",
      "Epoch:122 |Train Loss:0.026718598225020936|Valid Loss:0.02420226058789662\n",
      "\u001b[35mTime taken by epoch 122 is 0.80s\u001b[0m\n",
      "Epoch Started:123\n",
      "Epoch:123 |Train Loss:0.026985737129247615|Valid Loss:0.028470555586474284\n",
      "\u001b[35mTime taken by epoch 123 is 0.88s\u001b[0m\n",
      "Epoch Started:124\n",
      "Epoch:124 |Train Loss:0.02617004862986505|Valid Loss:0.028879167245967046\n",
      "\u001b[35mTime taken by epoch 124 is 0.60s\u001b[0m\n",
      "Epoch Started:125\n",
      "Epoch:125 |Train Loss:0.02585010333651943|Valid Loss:0.02091128152928182\n",
      "\u001b[32mLoss Decreased from 0.021537514935646738 to 0.02091128152928182\u001b[0m\n",
      "\u001b[35mTime taken by epoch 125 is 0.58s\u001b[0m\n",
      "Epoch Started:126\n",
      "Epoch:126 |Train Loss:0.026238999362768873|Valid Loss:0.04636332765221596\n",
      "\u001b[35mTime taken by epoch 126 is 0.81s\u001b[0m\n",
      "Epoch Started:127\n",
      "Epoch:127 |Train Loss:0.026329518561916693|Valid Loss:0.022985738968210562\n",
      "\u001b[35mTime taken by epoch 127 is 0.61s\u001b[0m\n",
      "Epoch Started:128\n",
      "Epoch:128 |Train Loss:0.02565630482110594|Valid Loss:0.024662180404577936\n",
      "\u001b[35mTime taken by epoch 128 is 0.57s\u001b[0m\n",
      "Epoch Started:129\n",
      "Epoch:129 |Train Loss:0.025811567603211318|Valid Loss:0.021434298184301172\n",
      "\u001b[35mTime taken by epoch 129 is 0.61s\u001b[0m\n",
      "Epoch Started:130\n",
      "Epoch:130 |Train Loss:0.026667474636009762|Valid Loss:0.027188581813658987\n",
      "\u001b[35mTime taken by epoch 130 is 0.54s\u001b[0m\n",
      "Epoch Started:131\n",
      "Epoch:131 |Train Loss:0.026406002829649618|Valid Loss:0.025667191350034306\n",
      "\u001b[35mTime taken by epoch 131 is 0.55s\u001b[0m\n",
      "Epoch Started:132\n",
      "Epoch:132 |Train Loss:0.02717528405732342|Valid Loss:0.04628630780747959\n",
      "\u001b[35mTime taken by epoch 132 is 0.56s\u001b[0m\n",
      "Epoch Started:133\n",
      "Epoch:133 |Train Loss:0.026277080843491212|Valid Loss:0.028085541778377125\n",
      "\u001b[35mTime taken by epoch 133 is 0.55s\u001b[0m\n",
      "Epoch Started:134\n",
      "Epoch:134 |Train Loss:0.025839647511020303|Valid Loss:0.0242571338479008\n",
      "\u001b[35mTime taken by epoch 134 is 0.53s\u001b[0m\n",
      "Epoch Started:135\n",
      "Epoch:135 |Train Loss:0.026221026799508503|Valid Loss:0.06372421075190816\n",
      "\u001b[35mTime taken by epoch 135 is 0.74s\u001b[0m\n",
      "Epoch Started:136\n",
      "Epoch:136 |Train Loss:0.02579693349876574|Valid Loss:0.02289469034544059\n",
      "\u001b[35mTime taken by epoch 136 is 0.56s\u001b[0m\n",
      "Epoch Started:137\n",
      "Epoch:137 |Train Loss:0.02640990387382252|Valid Loss:0.025036773777433803\n",
      "\u001b[35mTime taken by epoch 137 is 0.50s\u001b[0m\n",
      "Epoch Started:138\n",
      "Epoch:138 |Train Loss:0.02667159304421927|Valid Loss:0.03532314061054161\n",
      "\u001b[35mTime taken by epoch 138 is 0.51s\u001b[0m\n",
      "Epoch Started:139\n",
      "Epoch:139 |Train Loss:0.02631408129153507|Valid Loss:0.04317834334714072\n",
      "\u001b[35mTime taken by epoch 139 is 0.82s\u001b[0m\n",
      "Epoch Started:140\n",
      "Epoch:140 |Train Loss:0.026664255453007563|Valid Loss:0.0719133982700961\n",
      "\u001b[35mTime taken by epoch 140 is 0.66s\u001b[0m\n",
      "Epoch Started:141\n",
      "Epoch:141 |Train Loss:0.02743534916745765|Valid Loss:0.02423115074634552\n",
      "\u001b[35mTime taken by epoch 141 is 0.68s\u001b[0m\n",
      "Epoch Started:142\n",
      "Epoch:142 |Train Loss:0.026640335962708508|Valid Loss:0.029787576092141017\n",
      "\u001b[35mTime taken by epoch 142 is 0.54s\u001b[0m\n",
      "Epoch Started:143\n",
      "Epoch:143 |Train Loss:0.027167185708614334|Valid Loss:0.039143244070666175\n",
      "\u001b[35mTime taken by epoch 143 is 0.64s\u001b[0m\n",
      "Epoch Started:144\n",
      "Epoch:144 |Train Loss:0.026309820457494686|Valid Loss:0.027198005999837602\n",
      "\u001b[35mTime taken by epoch 144 is 0.64s\u001b[0m\n",
      "Epoch Started:145\n",
      "Epoch:145 |Train Loss:0.02616935023771865|Valid Loss:0.02789136501295226\n",
      "\u001b[35mTime taken by epoch 145 is 0.66s\u001b[0m\n",
      "Epoch Started:146\n",
      "Epoch:146 |Train Loss:0.02583576535939106|Valid Loss:0.0254499755267586\n",
      "\u001b[35mTime taken by epoch 146 is 0.53s\u001b[0m\n",
      "Epoch Started:147\n",
      "Epoch:147 |Train Loss:0.02615833348993744|Valid Loss:0.0505094187600272\n",
      "\u001b[35mTime taken by epoch 147 is 0.55s\u001b[0m\n",
      "Epoch Started:148\n",
      "Epoch:148 |Train Loss:0.026747704882706915|Valid Loss:0.04120778239199093\n",
      "\u001b[35mTime taken by epoch 148 is 0.59s\u001b[0m\n",
      "Epoch Started:149\n",
      "Epoch:149 |Train Loss:0.02643117119025971|Valid Loss:0.03707261436751911\n",
      "\u001b[35mTime taken by epoch 149 is 0.66s\u001b[0m\n",
      "Epoch Started:150\n",
      "Epoch:150 |Train Loss:0.02564279578759202|Valid Loss:0.022867165771978244\n",
      "\u001b[35mTime taken by epoch 150 is 0.51s\u001b[0m\n",
      "Epoch Started:151\n",
      "Epoch:151 |Train Loss:0.025997603245611702|Valid Loss:0.024032503233424256\n",
      "\u001b[35mTime taken by epoch 151 is 0.58s\u001b[0m\n",
      "Epoch Started:152\n",
      "Epoch:152 |Train Loss:0.025928814795666506|Valid Loss:0.02453483242009367\n",
      "\u001b[35mTime taken by epoch 152 is 0.53s\u001b[0m\n",
      "Epoch Started:153\n",
      "Epoch:153 |Train Loss:0.026878198043310216|Valid Loss:0.027384177914687564\n",
      "\u001b[35mTime taken by epoch 153 is 0.53s\u001b[0m\n",
      "Epoch Started:154\n",
      "Epoch:154 |Train Loss:0.02620948269031942|Valid Loss:0.022268942690321376\n",
      "\u001b[35mTime taken by epoch 154 is 0.58s\u001b[0m\n",
      "Epoch Started:155\n",
      "Epoch:155 |Train Loss:0.02564346806944481|Valid Loss:0.022158654938851084\n",
      "\u001b[35mTime taken by epoch 155 is 0.62s\u001b[0m\n",
      "Epoch Started:156\n",
      "Epoch:156 |Train Loss:0.02647692573788975|Valid Loss:0.02141700219362974\n",
      "\u001b[35mTime taken by epoch 156 is 0.64s\u001b[0m\n",
      "Epoch Started:157\n",
      "Epoch:157 |Train Loss:0.0349839860573411|Valid Loss:0.031536342576146126\n",
      "\u001b[35mTime taken by epoch 157 is 0.60s\u001b[0m\n",
      "Epoch Started:158\n",
      "Epoch:158 |Train Loss:0.030306738934346607|Valid Loss:0.03051812680704253\n",
      "\u001b[35mTime taken by epoch 158 is 0.55s\u001b[0m\n",
      "Epoch Started:159\n",
      "Epoch:159 |Train Loss:0.031049898991893445|Valid Loss:0.02988094011587756\n",
      "\u001b[35mTime taken by epoch 159 is 0.53s\u001b[0m\n",
      "Epoch Started:160\n",
      "Epoch:160 |Train Loss:0.029766281700826118|Valid Loss:0.024341788675103868\n",
      "\u001b[35mTime taken by epoch 160 is 0.56s\u001b[0m\n",
      "Epoch Started:161\n",
      "Epoch:161 |Train Loss:0.029338583449966142|Valid Loss:0.024985318205186298\n",
      "\u001b[35mTime taken by epoch 161 is 0.57s\u001b[0m\n",
      "Epoch Started:162\n",
      "Epoch:162 |Train Loss:0.02872669859789312|Valid Loss:0.025517328110124384\n",
      "\u001b[35mTime taken by epoch 162 is 0.69s\u001b[0m\n",
      "Epoch Started:163\n",
      "Epoch:163 |Train Loss:0.02846835892913597|Valid Loss:0.022865221170442446\n",
      "\u001b[35mTime taken by epoch 163 is 0.67s\u001b[0m\n",
      "Epoch Started:164\n",
      "Epoch:164 |Train Loss:0.027943015165094818|Valid Loss:0.024531852720039233\n",
      "\u001b[35mTime taken by epoch 164 is 0.65s\u001b[0m\n",
      "Epoch Started:165\n",
      "Epoch:165 |Train Loss:0.02833635955383735|Valid Loss:0.025039123238197396\n",
      "\u001b[35mTime taken by epoch 165 is 0.57s\u001b[0m\n",
      "Epoch Started:166\n",
      "Epoch:166 |Train Loss:0.037159464155722945|Valid Loss:0.14291172368185862\n",
      "\u001b[35mTime taken by epoch 166 is 0.72s\u001b[0m\n",
      "Epoch Started:167\n",
      "Epoch:167 |Train Loss:0.04041485781116145|Valid Loss:0.07870787701436452\n",
      "\u001b[35mTime taken by epoch 167 is 0.73s\u001b[0m\n",
      "Epoch Started:168\n",
      "Epoch:168 |Train Loss:0.03807621016832335|Valid Loss:0.28077671357563566\n",
      "\u001b[35mTime taken by epoch 168 is 0.63s\u001b[0m\n",
      "Epoch Started:169\n",
      "Epoch:169 |Train Loss:0.039684849857751815|Valid Loss:0.06830225139856339\n",
      "\u001b[35mTime taken by epoch 169 is 0.59s\u001b[0m\n",
      "Epoch Started:170\n",
      "Epoch:170 |Train Loss:0.033986896209950955|Valid Loss:0.02940852993300983\n",
      "\u001b[35mTime taken by epoch 170 is 0.57s\u001b[0m\n",
      "Epoch Started:171\n",
      "Epoch:171 |Train Loss:0.03247950575314462|Valid Loss:0.05855209061077663\n",
      "\u001b[35mTime taken by epoch 171 is 0.67s\u001b[0m\n",
      "Epoch Started:172\n",
      "Epoch:172 |Train Loss:0.03185091437106686|Valid Loss:0.05235031992197037\n",
      "\u001b[35mTime taken by epoch 172 is 0.57s\u001b[0m\n",
      "Epoch Started:173\n",
      "Epoch:173 |Train Loss:0.032134230547983735|Valid Loss:0.032792599339570315\n",
      "\u001b[35mTime taken by epoch 173 is 0.57s\u001b[0m\n",
      "Epoch Started:174\n",
      "Epoch:174 |Train Loss:0.030646712386182377|Valid Loss:0.030249959656170437\n",
      "\u001b[35mTime taken by epoch 174 is 0.65s\u001b[0m\n",
      "Epoch Started:175\n",
      "Epoch:175 |Train Loss:0.02966594456561974|Valid Loss:0.03384026326239109\n",
      "\u001b[35mTime taken by epoch 175 is 0.65s\u001b[0m\n",
      "Epoch Started:176\n",
      "Epoch:176 |Train Loss:0.029963546432554722|Valid Loss:0.025395851050104414\n",
      "\u001b[35mTime taken by epoch 176 is 0.80s\u001b[0m\n",
      "Epoch Started:177\n",
      "Epoch:177 |Train Loss:0.02944498136639595|Valid Loss:0.029602959752082825\n",
      "\u001b[35mTime taken by epoch 177 is 0.62s\u001b[0m\n",
      "Epoch Started:178\n",
      "Epoch:178 |Train Loss:0.03026975505053997|Valid Loss:0.026797388148094927\n",
      "\u001b[35mTime taken by epoch 178 is 0.60s\u001b[0m\n",
      "Epoch Started:179\n",
      "Epoch:179 |Train Loss:0.029373321183291928|Valid Loss:0.02613505401781627\n",
      "\u001b[35mTime taken by epoch 179 is 0.54s\u001b[0m\n",
      "Epoch Started:180\n",
      "Epoch:180 |Train Loss:0.029043913785634295|Valid Loss:0.024346923721688136\n",
      "\u001b[35mTime taken by epoch 180 is 0.53s\u001b[0m\n",
      "Epoch Started:181\n",
      "Epoch:181 |Train Loss:0.029622174899226854|Valid Loss:0.023400853254965374\n",
      "\u001b[35mTime taken by epoch 181 is 0.65s\u001b[0m\n",
      "Epoch Started:182\n",
      "Epoch:182 |Train Loss:0.02959719207137823|Valid Loss:0.03658507897385529\n",
      "\u001b[35mTime taken by epoch 182 is 0.63s\u001b[0m\n",
      "Epoch Started:183\n",
      "Epoch:183 |Train Loss:0.02978730244961168|Valid Loss:0.023910274463040487\n",
      "\u001b[35mTime taken by epoch 183 is 0.61s\u001b[0m\n",
      "Epoch Started:184\n",
      "Epoch:184 |Train Loss:0.02913074873919998|Valid Loss:0.027705447216119086\n",
      "\u001b[35mTime taken by epoch 184 is 0.69s\u001b[0m\n",
      "Epoch Started:185\n",
      "Epoch:185 |Train Loss:0.029524331047598804|Valid Loss:0.09377373648541314\n",
      "\u001b[35mTime taken by epoch 185 is 0.63s\u001b[0m\n",
      "Epoch Started:186\n",
      "Epoch:186 |Train Loss:0.02843278244004718|Valid Loss:0.02637372857757977\n",
      "\u001b[35mTime taken by epoch 186 is 0.68s\u001b[0m\n",
      "Epoch Started:187\n",
      "Epoch:187 |Train Loss:0.03402735113299319|Valid Loss:0.035318998619914055\n",
      "\u001b[35mTime taken by epoch 187 is 0.63s\u001b[0m\n",
      "Epoch Started:188\n",
      "Epoch:188 |Train Loss:0.0339457028146301|Valid Loss:0.031486038118600845\n",
      "\u001b[35mTime taken by epoch 188 is 0.62s\u001b[0m\n",
      "Epoch Started:189\n",
      "Epoch:189 |Train Loss:0.03508429059625736|Valid Loss:0.04057025536894798\n",
      "\u001b[35mTime taken by epoch 189 is 0.52s\u001b[0m\n",
      "Epoch Started:190\n",
      "Epoch:190 |Train Loss:0.0332630575368447|Valid Loss:0.06542036842022624\n",
      "\u001b[35mTime taken by epoch 190 is 0.63s\u001b[0m\n",
      "Epoch Started:191\n",
      "Epoch:191 |Train Loss:0.03354739524157984|Valid Loss:0.05845491800989423\n",
      "\u001b[35mTime taken by epoch 191 is 0.54s\u001b[0m\n",
      "Epoch Started:192\n",
      "Epoch:192 |Train Loss:0.03150572820699641|Valid Loss:0.04003883791821344\n",
      "\u001b[35mTime taken by epoch 192 is 0.56s\u001b[0m\n",
      "Epoch Started:193\n",
      "Epoch:193 |Train Loss:0.029546157024534687|Valid Loss:0.05712186066167695\n",
      "\u001b[35mTime taken by epoch 193 is 0.60s\u001b[0m\n",
      "Epoch Started:194\n",
      "Epoch:194 |Train Loss:0.028297639784536192|Valid Loss:0.03782927803695202\n",
      "\u001b[35mTime taken by epoch 194 is 0.61s\u001b[0m\n",
      "Epoch Started:195\n",
      "Epoch:195 |Train Loss:0.027255895281476632|Valid Loss:0.026572884725672857\n",
      "\u001b[35mTime taken by epoch 195 is 0.54s\u001b[0m\n",
      "Epoch Started:196\n",
      "Epoch:196 |Train Loss:0.026407930234979306|Valid Loss:0.08490456002099174\n",
      "\u001b[35mTime taken by epoch 196 is 0.73s\u001b[0m\n",
      "Epoch Started:197\n",
      "Epoch:197 |Train Loss:0.026864794548600912|Valid Loss:0.03756915219128132\n",
      "\u001b[35mTime taken by epoch 197 is 0.63s\u001b[0m\n",
      "Epoch Started:198\n",
      "Epoch:198 |Train Loss:0.026387263322249055|Valid Loss:0.024518743955663273\n",
      "\u001b[35mTime taken by epoch 198 is 0.55s\u001b[0m\n",
      "Epoch Started:199\n",
      "Epoch:199 |Train Loss:0.0267834225336888|Valid Loss:0.040567021284784587\n",
      "\u001b[35mTime taken by epoch 199 is 0.65s\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "best_loss, model = run(model,train_dl,val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMTpsModel(num_classes, input_size, hidden_size, num_layers,seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMTpsModel(\n",
       "  (lstm): LSTM(180, 360, num_layers=2, batch_first=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=360, out_features=45, bias=True)\n",
       "    (1): BatchNorm1d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=45, out_features=22, bias=True)\n",
       "    (4): BatchNorm1d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=22, out_features=11, bias=True)\n",
       "    (7): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Linear(in_features=11, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(config['best_model_name']))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.rollaxis(np.dstack(train_df2['features'].values.tolist()),-1).transpose(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = np.rollaxis(np.dstack(test_df2['features'].values.tolist()),-1).transpose(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1096, 18, 10) (365, 18, 9)\n"
     ]
    }
   ],
   "source": [
    "print(data_train.shape,data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_years_data = data_train[-seq_length:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 18, 10)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_years_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_df2)):\n",
    "        if i == 0:\n",
    "            inpt = torch.Tensor(last_years_data.reshape(seq_length,-1)).unsqueeze(dim=0)\n",
    "            # print(inpt.shape, i)\n",
    "        elif i < seq_length:\n",
    "            inpt1 = torch.Tensor(last_years_data[-seq_length+i:])\n",
    "            inpt2 = torch.Tensor(data_test[:i])\n",
    "            inpt3 = torch.cat(predictions[:i], dim=0).unsqueeze(dim=2)\n",
    "            inpt4 = torch.cat([inpt2,inpt3], dim=2)\n",
    "            \n",
    "            inpt = torch.cat([inpt1,inpt4],dim=0).reshape(seq_length,-1).unsqueeze(dim=0)\n",
    "            # print(inpt.shape, i)\n",
    "        else:\n",
    "            inpt2 = torch.Tensor(data_test[i-seq_length:i])\n",
    "            inpt3 = torch.cat(predictions[i-seq_length:i], dim=0).unsqueeze(dim=2)\n",
    "            inpt = torch.cat([inpt2,inpt3], dim=2).reshape(seq_length,-1).unsqueeze(dim=0)\n",
    "            # print(inpt.shape, i)\n",
    "        \n",
    "        \n",
    "        out = model(inpt)\n",
    "        predictions.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = [pred.squeeze().tolist() for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_df_test['num_sold_pred'] = final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_df_test = grp_df_test[['date','country','store','product','num_sold_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = grp_df_test.explode(['country','store','product','num_sold_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.152644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.217228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.892224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.393205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.74706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.367526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.463394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.194569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.183166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.920097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6570 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date country store product num_sold_pred\n",
       "0   2018-01-01       0     0       1     -0.152644\n",
       "0   2018-01-01       0     0       0      0.217228\n",
       "0   2018-01-01       0     0       2     -0.892224\n",
       "0   2018-01-01       0     1       1      0.393205\n",
       "0   2018-01-01       0     1       0       0.74706\n",
       "..         ...     ...   ...     ...           ...\n",
       "364 2018-12-31       2     0       0     -0.367526\n",
       "364 2018-12-31       2     0       2     -1.463394\n",
       "364 2018-12-31       2     1       1     -0.194569\n",
       "364 2018-12-31       2     1       0      0.183166\n",
       "364 2018-12-31       2     1       2     -0.920097\n",
       "\n",
       "[6570 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in ['country', 'product', 'store']:\n",
    "    test_results[feature] = le_dict[feature].inverse_transform(test_results[feature].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results['gdp'] = test_results.apply(get_gdp, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results['num_sold_pred'] = test_results.apply(lambda x: np.exp(x.num_sold_pred)* x.gdp, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = test_results.drop(columns = 'gdp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = original_test_df.merge(test_results, on = ['date','country','store','product'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>num_sold_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19728</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>405</td>\n",
       "      <td>236.567699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19729</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>621</td>\n",
       "      <td>342.443162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19730</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>176</td>\n",
       "      <td>112.917144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19731</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>714</td>\n",
       "      <td>408.333144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19732</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>1043</td>\n",
       "      <td>581.690318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>26293</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>823</td>\n",
       "      <td>384.622127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>26294</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>250</td>\n",
       "      <td>128.559706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>26295</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>1004</td>\n",
       "      <td>457.244509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>26296</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>1441</td>\n",
       "      <td>667.108977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>26297</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>388</td>\n",
       "      <td>221.337991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6570 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id       date  country       store         product  num_sold  \\\n",
       "0      19728 2018-01-01  Finland  KaggleMart      Kaggle Mug       405   \n",
       "1      19729 2018-01-01  Finland  KaggleMart      Kaggle Hat       621   \n",
       "2      19730 2018-01-01  Finland  KaggleMart  Kaggle Sticker       176   \n",
       "3      19731 2018-01-01  Finland  KaggleRama      Kaggle Mug       714   \n",
       "4      19732 2018-01-01  Finland  KaggleRama      Kaggle Hat      1043   \n",
       "...      ...        ...      ...         ...             ...       ...   \n",
       "6565   26293 2018-12-31   Sweden  KaggleMart      Kaggle Hat       823   \n",
       "6566   26294 2018-12-31   Sweden  KaggleMart  Kaggle Sticker       250   \n",
       "6567   26295 2018-12-31   Sweden  KaggleRama      Kaggle Mug      1004   \n",
       "6568   26296 2018-12-31   Sweden  KaggleRama      Kaggle Hat      1441   \n",
       "6569   26297 2018-12-31   Sweden  KaggleRama  Kaggle Sticker       388   \n",
       "\n",
       "      num_sold_pred  \n",
       "0        236.567699  \n",
       "1        342.443162  \n",
       "2        112.917144  \n",
       "3        408.333144  \n",
       "4        581.690318  \n",
       "...             ...  \n",
       "6565     384.622127  \n",
       "6566     128.559706  \n",
       "6567     457.244509  \n",
       "6568     667.108977  \n",
       "6569     221.337991  \n",
       "\n",
       "[6570 rows x 7 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape_loss_val = np.mean(smape_loss(test_results.num_sold.values, test_results.num_sold_pred.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.680312724013767"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smape_loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
