{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import dateutil.easter as easter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore, Back, Style\n",
    "r_ = Fore.RED\n",
    "b_ = Fore.BLUE\n",
    "c_ = Fore.CYAN\n",
    "g_ = Fore.GREEN\n",
    "y_ = Fore.YELLOW\n",
    "m_ = Fore.MAGENTA\n",
    "sr_ = Style.RESET_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nModel 1 is be multivariate timeseries, each variate represents unique country,store, product\\n\\nWe have 3 countries, 2 stores and 3 products, this means we need to predict 3*2*3 18 values representing each.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### \n",
    "'''\n",
    "Model 1 is be multivariate timeseries, each variate represents unique country,store, product\n",
    "\n",
    "We have 3 countries, 2 stores and 3 products, this means we need to predict 3*2*3 18 values representing each.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id       date  country       store     product  num_sold\n",
       "0       0 2015-01-01  Finland  KaggleMart  Kaggle Mug       329\n",
       "1       1 2015-01-01  Finland  KaggleMart  Kaggle Hat       520"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_train_df = pd.read_csv('./data/train.csv', parse_dates=['date'])\n",
    "original_test_df = pd.read_csv('./data//test.csv', parse_dates=['date'])\n",
    "gdp_df = pd.read_csv('./data/GDP_data_2015_to_2019_Finland_Norway_Sweden.csv',\n",
    "                    index_col='year')\n",
    "\n",
    "original_train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Kaggle Mug', 'Kaggle Hat', 'Kaggle Sticker'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_train_df['product'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def smape_loss(y_true, y_pred):\n",
    "    \"\"\"SMAPE Loss\"\"\"\n",
    "    return np.abs(y_true - y_pred) / (y_true + np.abs(y_pred)) * 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP_Finland</th>\n",
       "      <th>GDP_Norway</th>\n",
       "      <th>GDP_Sweden</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>234.440</td>\n",
       "      <td>385.802</td>\n",
       "      <td>505.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>240.608</td>\n",
       "      <td>368.827</td>\n",
       "      <td>515.655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>255.017</td>\n",
       "      <td>398.394</td>\n",
       "      <td>541.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>275.580</td>\n",
       "      <td>437.000</td>\n",
       "      <td>555.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>268.782</td>\n",
       "      <td>405.510</td>\n",
       "      <td>533.880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      GDP_Finland  GDP_Norway  GDP_Sweden\n",
       "year                                     \n",
       "2015      234.440     385.802     505.104\n",
       "2016      240.608     368.827     515.655\n",
       "2017      255.017     398.394     541.019\n",
       "2018      275.580     437.000     555.455\n",
       "2019      268.782     405.510     533.880"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "def get_gdp(row):\n",
    "    \"\"\"Return the GDP based on row.country and row.date.year\"\"\"\n",
    "    country = 'GDP_' + row.country\n",
    "    return gdp_df.loc[row.date.year, country]\n",
    "\n",
    "le_dict = {feature: LabelEncoder().fit(original_train_df[feature]) for feature in ['country', 'product', 'store']}\n",
    "\n",
    "def engineer(df):\n",
    "    \"\"\"Return a new dataframe with the engineered features\"\"\"\n",
    "    \n",
    "    new_df = pd.DataFrame({'gdp': df.apply(get_gdp, axis=1),\n",
    "                           'dayofyear': df.date.dt.dayofyear,\n",
    "                           'wd4': df.date.dt.weekday == 4, # Friday\n",
    "                           'wd56': df.date.dt.weekday >= 5, # Saturday and Sunday\n",
    "                          })\n",
    "\n",
    "    new_df.loc[(df.date.dt.year != 2016) & (df.date.dt.month >=3), 'dayofyear'] += 1 # fix for leap years\n",
    "    \n",
    "    for feature in ['country', 'product', 'store']:\n",
    "        new_df[feature] = le_dict[feature].transform(df[feature])\n",
    "        \n",
    "    # Easter\n",
    "    easter_date = df.date.apply(lambda date: pd.Timestamp(easter.easter(date.year)))\n",
    "    new_df['days_from_easter'] = (df.date - easter_date).dt.days.clip(-5, 65)\n",
    "    \n",
    "    # Last Sunday of May (Mother's Day)\n",
    "    sun_may_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-5-31')),\n",
    "                                         2016: pd.Timestamp(('2016-5-29')),\n",
    "                                         2017: pd.Timestamp(('2017-5-28')),\n",
    "                                         2018: pd.Timestamp(('2018-5-27')),\n",
    "                                         2019: pd.Timestamp(('2019-5-26'))})\n",
    "    #new_df['days_from_sun_may'] = (df.date - sun_may_date).dt.days.clip(-1, 9)\n",
    "    \n",
    "    # Last Wednesday of June\n",
    "    wed_june_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-06-24')),\n",
    "                                         2016: pd.Timestamp(('2016-06-29')),\n",
    "                                         2017: pd.Timestamp(('2017-06-28')),\n",
    "                                         2018: pd.Timestamp(('2018-06-27')),\n",
    "                                         2019: pd.Timestamp(('2019-06-26'))})\n",
    "    new_df['days_from_wed_jun'] = (df.date - wed_june_date).dt.days.clip(-5, 5)\n",
    "    \n",
    "    # First Sunday of November (second Sunday is Father's Day)\n",
    "    sun_nov_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-11-1')),\n",
    "                                         2016: pd.Timestamp(('2016-11-6')),\n",
    "                                         2017: pd.Timestamp(('2017-11-5')),\n",
    "                                         2018: pd.Timestamp(('2018-11-4')),\n",
    "                                         2019: pd.Timestamp(('2019-11-3'))})\n",
    "    new_df['days_from_sun_nov'] = (df.date - sun_nov_date).dt.days.clip(-1, 9)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "train_df = engineer(original_train_df)\n",
    "train_df['date'] = original_train_df.date # used in GroupKFold\n",
    "train_df['num_sold'] = original_train_df.num_sold.astype(np.float32)\n",
    "train_df['target'] = np.log(train_df['num_sold'] / train_df['gdp'])\n",
    "test_df = engineer(original_test_df)\n",
    "test_df['date'] = original_test_df.date # used in GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gdp</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>wd4</th>\n",
       "      <th>wd56</th>\n",
       "      <th>country</th>\n",
       "      <th>product</th>\n",
       "      <th>store</th>\n",
       "      <th>days_from_easter</th>\n",
       "      <th>days_from_wed_jun</th>\n",
       "      <th>days_from_sun_nov</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>268.782</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>268.782</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>268.782</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>268.782</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>268.782</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>533.880</td>\n",
       "      <td>366</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2019-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>533.880</td>\n",
       "      <td>366</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2019-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>533.880</td>\n",
       "      <td>366</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2019-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>533.880</td>\n",
       "      <td>366</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2019-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>533.880</td>\n",
       "      <td>366</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2019-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6570 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          gdp  dayofyear    wd4   wd56  country  product  store  \\\n",
       "0     268.782          1  False  False        0        1      0   \n",
       "1     268.782          1  False  False        0        0      0   \n",
       "2     268.782          1  False  False        0        2      0   \n",
       "3     268.782          1  False  False        0        1      1   \n",
       "4     268.782          1  False  False        0        0      1   \n",
       "...       ...        ...    ...    ...      ...      ...    ...   \n",
       "6565  533.880        366  False  False        2        0      0   \n",
       "6566  533.880        366  False  False        2        2      0   \n",
       "6567  533.880        366  False  False        2        1      1   \n",
       "6568  533.880        366  False  False        2        0      1   \n",
       "6569  533.880        366  False  False        2        2      1   \n",
       "\n",
       "      days_from_easter  days_from_wed_jun  days_from_sun_nov       date  \n",
       "0                   -5                 -5                 -1 2019-01-01  \n",
       "1                   -5                 -5                 -1 2019-01-01  \n",
       "2                   -5                 -5                 -1 2019-01-01  \n",
       "3                   -5                 -5                 -1 2019-01-01  \n",
       "4                   -5                 -5                 -1 2019-01-01  \n",
       "...                ...                ...                ...        ...  \n",
       "6565                65                  5                  9 2019-12-31  \n",
       "6566                65                  5                  9 2019-12-31  \n",
       "6567                65                  5                  9 2019-12-31  \n",
       "6568                65                  5                  9 2019-12-31  \n",
       "6569                65                  5                  9 2019-12-31  \n",
       "\n",
       "[6570 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_features = ['dayofyear', 'days_from_easter', 'days_from_sun_nov', 'days_from_wed_jun', 'wd4', 'wd56','country','store','product', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gdp</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>wd4</th>\n",
       "      <th>wd56</th>\n",
       "      <th>country</th>\n",
       "      <th>product</th>\n",
       "      <th>store</th>\n",
       "      <th>days_from_easter</th>\n",
       "      <th>days_from_wed_jun</th>\n",
       "      <th>days_from_sun_nov</th>\n",
       "      <th>date</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>234.440</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>329.0</td>\n",
       "      <td>0.338858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>234.440</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.796629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>234.440</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>146.0</td>\n",
       "      <td>-0.473593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>234.440</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>572.0</td>\n",
       "      <td>0.891939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>234.440</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>911.0</td>\n",
       "      <td>1.357343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26293</th>\n",
       "      <td>555.455</td>\n",
       "      <td>366</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>823.0</td>\n",
       "      <td>0.393169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26294</th>\n",
       "      <td>555.455</td>\n",
       "      <td>366</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>250.0</td>\n",
       "      <td>-0.798327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26295</th>\n",
       "      <td>555.455</td>\n",
       "      <td>366</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>0.591960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26296</th>\n",
       "      <td>555.455</td>\n",
       "      <td>366</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1441.0</td>\n",
       "      <td>0.953305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26297</th>\n",
       "      <td>555.455</td>\n",
       "      <td>366</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>388.0</td>\n",
       "      <td>-0.358782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26298 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           gdp  dayofyear    wd4   wd56  country  product  store  \\\n",
       "0      234.440          1  False  False        0        1      0   \n",
       "1      234.440          1  False  False        0        0      0   \n",
       "2      234.440          1  False  False        0        2      0   \n",
       "3      234.440          1  False  False        0        1      1   \n",
       "4      234.440          1  False  False        0        0      1   \n",
       "...        ...        ...    ...    ...      ...      ...    ...   \n",
       "26293  555.455        366  False  False        2        0      0   \n",
       "26294  555.455        366  False  False        2        2      0   \n",
       "26295  555.455        366  False  False        2        1      1   \n",
       "26296  555.455        366  False  False        2        0      1   \n",
       "26297  555.455        366  False  False        2        2      1   \n",
       "\n",
       "       days_from_easter  days_from_wed_jun  days_from_sun_nov       date  \\\n",
       "0                    -5                 -5                 -1 2015-01-01   \n",
       "1                    -5                 -5                 -1 2015-01-01   \n",
       "2                    -5                 -5                 -1 2015-01-01   \n",
       "3                    -5                 -5                 -1 2015-01-01   \n",
       "4                    -5                 -5                 -1 2015-01-01   \n",
       "...                 ...                ...                ...        ...   \n",
       "26293                65                  5                  9 2018-12-31   \n",
       "26294                65                  5                  9 2018-12-31   \n",
       "26295                65                  5                  9 2018-12-31   \n",
       "26296                65                  5                  9 2018-12-31   \n",
       "26297                65                  5                  9 2018-12-31   \n",
       "\n",
       "       num_sold    target  \n",
       "0         329.0  0.338858  \n",
       "1         520.0  0.796629  \n",
       "2         146.0 -0.473593  \n",
       "3         572.0  0.891939  \n",
       "4         911.0  1.357343  \n",
       "...         ...       ...  \n",
       "26293     823.0  0.393169  \n",
       "26294     250.0 -0.798327  \n",
       "26295    1004.0  0.591960  \n",
       "26296    1441.0  0.953305  \n",
       "26297     388.0 -0.358782  \n",
       "\n",
       "[26298 rows x 13 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grp_df_train = train_df.groupby('date', as_index=False).agg(target = ('target', list),\n",
    "                             dayofyear =('dayofyear', list),\n",
    "                             wd4 =('wd4', list),\n",
    "                             wd56 = ('wd56', list),\n",
    "                             country =('country', list),\n",
    "                             product =('product', list),\n",
    "                             store =('store', list),\n",
    "                             days_from_easter =('days_from_easter', list),\n",
    "                             days_from_wed_jun =('days_from_wed_jun', list),\n",
    "                             days_from_sun_nov =('days_from_sun_nov', list),\n",
    "                            )\n",
    "\n",
    "train_df2 = pd.DataFrame({'date': grp_df_train['date'].values,\n",
    "              'features':grp_df_train.apply(lambda x: np.array([np.array(x[f]) for f in in_features]), axis=1)  \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grp_df_test = test_df.groupby('date', as_index=False).agg(\n",
    "                             dayofyear =('dayofyear', list),\n",
    "                             wd4 =('wd4', list),\n",
    "                             wd56 = ('wd56', list),\n",
    "                             country =('country', list),\n",
    "                             product =('product', list),\n",
    "                             store =('store', list),\n",
    "                             days_from_easter =('days_from_easter', list),\n",
    "                             days_from_wed_jun =('days_from_wed_jun', list),\n",
    "                             days_from_sun_nov =('days_from_sun_nov', list),\n",
    "                            )\n",
    "\n",
    "test_df2 = pd.DataFrame({'date': grp_df_test['date'].values,\n",
    "              'features':grp_df_test.apply(lambda x: np.array([np.array(x[f]) for f in in_features if f!='target']), axis=1)  \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'seq_length' : 60,\n",
    "    'num_epochs' : 200,\n",
    "    'lr' : 0.001,\n",
    "    'input_size' : 180,\n",
    "    'hidden_size' : 360,\n",
    "    'num_layers' : 2,\n",
    "    'num_classes' :18, ## This is  output dimension\n",
    "    'train_shuffle': True,\n",
    "    'val_shuffle': True,\n",
    "    'batch_size' : 30,\n",
    "    'best_model_name' : 'lstm_tsp_mlp_head_drpOut_1.bin',\n",
    "    'bidirectional' : False,\n",
    "    'only_last_hidden': False\n",
    "}\n",
    "# config_lr = {'T_max':20,\n",
    "#              'eta_min':0\n",
    "#             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sequences ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(data, seq_length):\n",
    "        x = []\n",
    "        y = []\n",
    "\n",
    "        for i in range(len(data)-seq_length-1):\n",
    "            _x = data[i:(i+seq_length),:].transpose(0,2,1).reshape(seq_length,-1)\n",
    "            _y = data[i+seq_length,-1]\n",
    "            x.append(_x)\n",
    "            y.append(_y)\n",
    "\n",
    "        return np.array(x),np.array(y)\n",
    "    \n",
    "def make_sequences(df,seq_length):\n",
    "    data = np.rollaxis(np.dstack(df['features'].values.tolist()),-1)\n",
    "    print('Data Shape', data.shape)\n",
    "    \n",
    "    x, y = sliding_windows(data, seq_length)\n",
    "\n",
    "    print('X,y shapes', x.shape,y.shape)\n",
    "    \n",
    "    return x,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape (1461, 10, 18)\n",
      "X,y shapes (1400, 60, 180) (1400, 18)\n"
     ]
    }
   ],
   "source": [
    "X,y = make_sequences(train_df2,config['seq_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TPSDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x,y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        \"\"\"\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = [torch.Tensor(self.x[idx]), torch.Tensor(self.y[idx])]\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = config['num_epochs']\n",
    "lr = config['lr']\n",
    "input_size = config['input_size']\n",
    "hidden_size = config['hidden_size']\n",
    "num_layers = config['num_layers']\n",
    "num_classes = config['num_classes']\n",
    "seq_length = config['seq_length']\n",
    "bidirectional = config['bidirectional']\n",
    "only_last_hidden = config['only_last_hidden']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTMTpsModel(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers,seq_length):\n",
    "        super(LSTMTpsModel, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True,bidirectional=bidirectional)\n",
    "        \n",
    "        if bidirectional:\n",
    "            m=2\n",
    "        else:\n",
    "            m=1\n",
    "        \n",
    "        if only_last_hidden:\n",
    "            input_dim = hidden_size*m\n",
    "        else:\n",
    "            input_dim = self.seq_length*hidden_size*m\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Linear(input_dim, input_dim//8),\n",
    "                                # nn.BatchNorm1d(num_features=input_dim//8),\n",
    "                                nn.Dropout(0.2),\n",
    "                                nn.ReLU(),\n",
    "                                \n",
    "                                nn.Linear(input_dim//8, input_dim//16),\n",
    "                                # nn.BatchNorm1d(num_features=input_dim//16),\n",
    "                                nn.Dropout(0.2),\n",
    "                                nn.ReLU(),\n",
    "                                \n",
    "                                nn.Linear(input_dim//16, input_dim//32),\n",
    "                                # nn.BatchNorm1d(num_features=input_dim//32),\n",
    "                                nn.Dropout(0.2),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(input_dim//32, self.num_classes)\n",
    "                                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Propagate input through LSTM\n",
    "        h_out, (_, _) = self.lstm(x)\n",
    "        if only_last_hidden:\n",
    "            h_out = h_out[:,-1:,:]\n",
    "        h_out = h_out.flatten(start_dim=1)\n",
    "        \n",
    "        out = self.fc(h_out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model,train_dl,val_dl):\n",
    "    def evaluate(model,valid_loader):\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        rec_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for i, inputs in enumerate(valid_loader):\n",
    "                dataX = inputs[0]\n",
    "                dataY = inputs[1]\n",
    "                outputs = model(dataX)\n",
    "                loss = criterion(outputs, dataY)\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "        valid_loss /= len(valid_loader)\n",
    "        return valid_loss\n",
    "    \n",
    "    def train_and_evaluate_loop(train_loader,model,optimizer,criterion,epoch,lr_scheduler=None,valid_loader=None, best_loss=99999):\n",
    "        train_loss = 0\n",
    "        for i, inputs in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            model.train()\n",
    "            \n",
    "            dataX = inputs[0]\n",
    "            dataY = inputs[1]\n",
    "            outputs = model(dataX)\n",
    "            loss = criterion(outputs, dataY)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            if lr_scheduler:\n",
    "                lr_scheduler.step()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        if valid_loader:\n",
    "            valid_loss = evaluate(model,valid_loader) \n",
    "            print(f\"Epoch:{epoch} |Train Loss:{train_loss}|Valid Loss:{valid_loss}\")\n",
    "            if valid_loss <= best_loss:\n",
    "                print(f\"{g_}Loss Decreased from {best_loss} to {valid_loss}{sr_}\")\n",
    "\n",
    "                best_loss = valid_loss\n",
    "                torch.save(model.state_dict(), config['best_model_name'])\n",
    "        else:\n",
    "            print(f\"Epoch:{epoch} |Train Loss:{train_loss}\")\n",
    "            \n",
    "                    \n",
    "        return best_loss\n",
    "    \n",
    "    accelerator = Accelerator()\n",
    "    print(f\"{accelerator.device} is used\")\n",
    "\n",
    "    \n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(),lr=config['lr'],amsgrad=False)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    lr_scheduler = None\n",
    "    # lr_scheduler =  torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, **config_lr)\n",
    "\n",
    "    model,train_dl,val_dl,optimizer,lr_scheduler,criterion = accelerator.prepare(model,train_dl,val_dl,optimizer,lr_scheduler,criterion)\n",
    "\n",
    "    best_loss = 9999999\n",
    "    start_time = time.time()\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        print(f\"Epoch Started:{epoch}\")\n",
    "        best_loss = train_and_evaluate_loop(train_dl,model,optimizer,criterion,epoch,lr_scheduler,valid_loader=val_dl, best_loss=best_loss)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"{m_}Time taken by epoch {epoch} is {end_time-start_time:.2f}s{sr_}\")\n",
    "        start_time = end_time\n",
    "        \n",
    "    return best_loss, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMTpsModel(num_classes, input_size, hidden_size, num_layers,seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(TPSDataset(X_train, y_train), batch_size=config['batch_size'], shuffle=config['train_shuffle'], num_workers=2)\n",
    "val_dl = DataLoader(TPSDataset(X_val, y_val), batch_size=config['batch_size'], shuffle=config['train_shuffle'], num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n",
      "Epoch Started:0\n",
      "Epoch:0 |Train Loss:0.18878438235505632|Valid Loss:0.037116770073771475\n",
      "\u001b[32mLoss Decreased from 9999999 to 0.037116770073771475\u001b[0m\n",
      "\u001b[35mTime taken by epoch 0 is 2.96s\u001b[0m\n",
      "Epoch Started:1\n",
      "Epoch:1 |Train Loss:0.04778810389535992|Valid Loss:0.030099331773817538\n",
      "\u001b[32mLoss Decreased from 0.037116770073771475 to 0.030099331773817538\u001b[0m\n",
      "\u001b[35mTime taken by epoch 1 is 1.81s\u001b[0m\n",
      "Epoch Started:2\n",
      "Epoch:2 |Train Loss:0.039293781609127394|Valid Loss:0.029937287978827953\n",
      "\u001b[32mLoss Decreased from 0.030099331773817538 to 0.029937287978827953\u001b[0m\n",
      "\u001b[35mTime taken by epoch 2 is 1.78s\u001b[0m\n",
      "Epoch Started:3\n",
      "Epoch:3 |Train Loss:0.03586163259062328|Valid Loss:0.026530300080776215\n",
      "\u001b[32mLoss Decreased from 0.029937287978827953 to 0.026530300080776215\u001b[0m\n",
      "\u001b[35mTime taken by epoch 3 is 1.93s\u001b[0m\n",
      "Epoch Started:4\n",
      "Epoch:4 |Train Loss:0.03951118768830048|Valid Loss:0.038379752077162266\n",
      "\u001b[35mTime taken by epoch 4 is 1.17s\u001b[0m\n",
      "Epoch Started:5\n",
      "Epoch:5 |Train Loss:0.035010789472021554|Valid Loss:0.026493257191032172\n",
      "\u001b[32mLoss Decreased from 0.026530300080776215 to 0.026493257191032172\u001b[0m\n",
      "\u001b[35mTime taken by epoch 5 is 1.71s\u001b[0m\n",
      "Epoch Started:6\n",
      "Epoch:6 |Train Loss:0.032932556038232225|Valid Loss:0.02711514215916395\n",
      "\u001b[35mTime taken by epoch 6 is 1.18s\u001b[0m\n",
      "Epoch Started:7\n",
      "Epoch:7 |Train Loss:0.03638280143863276|Valid Loss:0.03991502169519663\n",
      "\u001b[35mTime taken by epoch 7 is 1.15s\u001b[0m\n",
      "Epoch Started:8\n",
      "Epoch:8 |Train Loss:0.041139757358714155|Valid Loss:0.041675445064902304\n",
      "\u001b[35mTime taken by epoch 8 is 1.24s\u001b[0m\n",
      "Epoch Started:9\n",
      "Epoch:9 |Train Loss:0.03880090384106887|Valid Loss:0.0380538446828723\n",
      "\u001b[35mTime taken by epoch 9 is 1.23s\u001b[0m\n",
      "Epoch Started:10\n",
      "Epoch:10 |Train Loss:0.03744621805258488|Valid Loss:0.02887883586809039\n",
      "\u001b[35mTime taken by epoch 10 is 1.24s\u001b[0m\n",
      "Epoch Started:11\n",
      "Epoch:11 |Train Loss:0.03371480519050046|Valid Loss:0.02640361338853836\n",
      "\u001b[32mLoss Decreased from 0.026493257191032172 to 0.02640361338853836\u001b[0m\n",
      "\u001b[35mTime taken by epoch 11 is 1.69s\u001b[0m\n",
      "Epoch Started:12\n",
      "Epoch:12 |Train Loss:0.03238298552797029|Valid Loss:0.030098694190382958\n",
      "\u001b[35mTime taken by epoch 12 is 1.17s\u001b[0m\n",
      "Epoch Started:13\n",
      "Epoch:13 |Train Loss:0.03145116719564325|Valid Loss:0.025830903090536594\n",
      "\u001b[32mLoss Decreased from 0.02640361338853836 to 0.025830903090536594\u001b[0m\n",
      "\u001b[35mTime taken by epoch 13 is 1.65s\u001b[0m\n",
      "Epoch Started:14\n",
      "Epoch:14 |Train Loss:0.028561698321841265|Valid Loss:0.025023224484175443\n",
      "\u001b[32mLoss Decreased from 0.025830903090536594 to 0.025023224484175443\u001b[0m\n",
      "\u001b[35mTime taken by epoch 14 is 1.63s\u001b[0m\n",
      "Epoch Started:15\n",
      "Epoch:15 |Train Loss:0.027516369756899382|Valid Loss:0.028185094147920607\n",
      "\u001b[35mTime taken by epoch 15 is 1.08s\u001b[0m\n",
      "Epoch Started:16\n",
      "Epoch:16 |Train Loss:0.028572852380181615|Valid Loss:0.02245691856369376\n",
      "\u001b[32mLoss Decreased from 0.025023224484175443 to 0.02245691856369376\u001b[0m\n",
      "\u001b[35mTime taken by epoch 16 is 1.80s\u001b[0m\n",
      "Epoch Started:17\n",
      "Epoch:17 |Train Loss:0.027081462015446863|Valid Loss:0.021704436093568803\n",
      "\u001b[32mLoss Decreased from 0.02245691856369376 to 0.021704436093568803\u001b[0m\n",
      "\u001b[35mTime taken by epoch 17 is 1.71s\u001b[0m\n",
      "Epoch Started:18\n",
      "Epoch:18 |Train Loss:0.027262061197114617|Valid Loss:0.02648334726691246\n",
      "\u001b[35mTime taken by epoch 18 is 1.20s\u001b[0m\n",
      "Epoch Started:19\n",
      "Epoch:19 |Train Loss:0.02608812673899688|Valid Loss:0.02358812540769577\n",
      "\u001b[35mTime taken by epoch 19 is 1.08s\u001b[0m\n",
      "Epoch Started:20\n",
      "Epoch:20 |Train Loss:0.027948517940546338|Valid Loss:0.03235093001276255\n",
      "\u001b[35mTime taken by epoch 20 is 1.05s\u001b[0m\n",
      "Epoch Started:21\n",
      "Epoch:21 |Train Loss:0.028514321697385686|Valid Loss:0.022315947338938713\n",
      "\u001b[35mTime taken by epoch 21 is 1.06s\u001b[0m\n",
      "Epoch Started:22\n",
      "Epoch:22 |Train Loss:0.029691726753586216|Valid Loss:0.03392428532242775\n",
      "\u001b[35mTime taken by epoch 22 is 1.07s\u001b[0m\n",
      "Epoch Started:23\n",
      "Epoch:23 |Train Loss:0.02698460824199413|Valid Loss:0.029134469106793404\n",
      "\u001b[35mTime taken by epoch 23 is 1.08s\u001b[0m\n",
      "Epoch Started:24\n",
      "Epoch:24 |Train Loss:0.024340658767246885|Valid Loss:0.021392264030873777\n",
      "\u001b[32mLoss Decreased from 0.021704436093568803 to 0.021392264030873777\u001b[0m\n",
      "\u001b[35mTime taken by epoch 24 is 1.71s\u001b[0m\n",
      "Epoch Started:25\n",
      "Epoch:25 |Train Loss:0.023224284333225927|Valid Loss:0.020599893759936094\n",
      "\u001b[32mLoss Decreased from 0.021392264030873777 to 0.020599893759936094\u001b[0m\n",
      "\u001b[35mTime taken by epoch 25 is 1.78s\u001b[0m\n",
      "Epoch Started:26\n",
      "Epoch:26 |Train Loss:0.021179680810555032|Valid Loss:0.019975416269153355\n",
      "\u001b[32mLoss Decreased from 0.020599893759936094 to 0.019975416269153355\u001b[0m\n",
      "\u001b[35mTime taken by epoch 26 is 1.54s\u001b[0m\n",
      "Epoch Started:27\n",
      "Epoch:27 |Train Loss:0.02558231348858068|Valid Loss:0.0173418871127069\n",
      "\u001b[32mLoss Decreased from 0.019975416269153355 to 0.0173418871127069\u001b[0m\n",
      "\u001b[35mTime taken by epoch 27 is 1.46s\u001b[0m\n",
      "Epoch Started:28\n",
      "Epoch:28 |Train Loss:0.01948029829777385|Valid Loss:0.019064934365451335\n",
      "\u001b[35mTime taken by epoch 28 is 1.11s\u001b[0m\n",
      "Epoch Started:29\n",
      "Epoch:29 |Train Loss:0.024093217902669783|Valid Loss:0.024179342668503523\n",
      "\u001b[35mTime taken by epoch 29 is 1.01s\u001b[0m\n",
      "Epoch Started:30\n",
      "Epoch:30 |Train Loss:0.02013941795418137|Valid Loss:0.018597539886832236\n",
      "\u001b[35mTime taken by epoch 30 is 0.99s\u001b[0m\n",
      "Epoch Started:31\n",
      "Epoch:31 |Train Loss:0.021256410320730584|Valid Loss:0.016160371340811254\n",
      "\u001b[32mLoss Decreased from 0.0173418871127069 to 0.016160371340811254\u001b[0m\n",
      "\u001b[35mTime taken by epoch 31 is 1.52s\u001b[0m\n",
      "Epoch Started:32\n",
      "Epoch:32 |Train Loss:0.01965144291324051|Valid Loss:0.01838634079322219\n",
      "\u001b[35mTime taken by epoch 32 is 1.12s\u001b[0m\n",
      "Epoch Started:33\n",
      "Epoch:33 |Train Loss:0.01955291045535552|Valid Loss:0.019022107869386674\n",
      "\u001b[35mTime taken by epoch 33 is 1.31s\u001b[0m\n",
      "Epoch Started:34\n",
      "Epoch:34 |Train Loss:0.02243039592806446|Valid Loss:0.017264331225305796\n",
      "\u001b[35mTime taken by epoch 34 is 1.01s\u001b[0m\n",
      "Epoch Started:35\n",
      "Epoch:35 |Train Loss:0.02073527855406466|Valid Loss:0.02622219640761614\n",
      "\u001b[35mTime taken by epoch 35 is 1.07s\u001b[0m\n",
      "Epoch Started:36\n",
      "Epoch:36 |Train Loss:0.02398380191114388|Valid Loss:0.027540623862296342\n",
      "\u001b[35mTime taken by epoch 36 is 1.03s\u001b[0m\n",
      "Epoch Started:37\n",
      "Epoch:37 |Train Loss:0.030408493218649375|Valid Loss:0.028829917125403882\n",
      "\u001b[35mTime taken by epoch 37 is 1.08s\u001b[0m\n",
      "Epoch Started:38\n",
      "Epoch:38 |Train Loss:0.027687972730123682|Valid Loss:0.033116800524294374\n",
      "\u001b[35mTime taken by epoch 38 is 1.04s\u001b[0m\n",
      "Epoch Started:39\n",
      "Epoch:39 |Train Loss:0.02728242591317547|Valid Loss:0.028539539128541947\n",
      "\u001b[35mTime taken by epoch 39 is 1.04s\u001b[0m\n",
      "Epoch Started:40\n",
      "Epoch:40 |Train Loss:0.02837067200361114|Valid Loss:0.025326292123645545\n",
      "\u001b[35mTime taken by epoch 40 is 1.08s\u001b[0m\n",
      "Epoch Started:41\n",
      "Epoch:41 |Train Loss:0.02748526676901077|Valid Loss:0.04413586799055338\n",
      "\u001b[35mTime taken by epoch 41 is 1.44s\u001b[0m\n",
      "Epoch Started:42\n",
      "Epoch:42 |Train Loss:0.03556854812134253|Valid Loss:0.02951274048537016\n",
      "\u001b[35mTime taken by epoch 42 is 1.31s\u001b[0m\n",
      "Epoch Started:43\n",
      "Epoch:43 |Train Loss:0.02855953510458532|Valid Loss:0.02887790501117706\n",
      "\u001b[35mTime taken by epoch 43 is 1.03s\u001b[0m\n",
      "Epoch Started:44\n",
      "Epoch:44 |Train Loss:0.02545188029149645|Valid Loss:0.023065028805285694\n",
      "\u001b[35mTime taken by epoch 44 is 1.10s\u001b[0m\n",
      "Epoch Started:45\n",
      "Epoch:45 |Train Loss:0.02210876970600925|Valid Loss:0.018820964451879262\n",
      "\u001b[35mTime taken by epoch 45 is 1.04s\u001b[0m\n",
      "Epoch Started:46\n",
      "Epoch:46 |Train Loss:0.01947162440046668|Valid Loss:0.01949475733563304\n",
      "\u001b[35mTime taken by epoch 46 is 1.04s\u001b[0m\n",
      "Epoch Started:47\n",
      "Epoch:47 |Train Loss:0.01795751478915152|Valid Loss:0.019077400397509336\n",
      "\u001b[35mTime taken by epoch 47 is 1.02s\u001b[0m\n",
      "Epoch Started:48\n",
      "Epoch:48 |Train Loss:0.016199515789355103|Valid Loss:0.014330834709107875\n",
      "\u001b[32mLoss Decreased from 0.016160371340811254 to 0.014330834709107875\u001b[0m\n",
      "\u001b[35mTime taken by epoch 48 is 1.49s\u001b[0m\n",
      "Epoch Started:49\n",
      "Epoch:49 |Train Loss:0.01502876236152492|Valid Loss:0.012062108842656016\n",
      "\u001b[32mLoss Decreased from 0.014330834709107875 to 0.012062108842656016\u001b[0m\n",
      "\u001b[35mTime taken by epoch 49 is 1.57s\u001b[0m\n",
      "Epoch Started:50\n",
      "Epoch:50 |Train Loss:0.01637463220150063|Valid Loss:0.01723160520195961\n",
      "\u001b[35mTime taken by epoch 50 is 1.00s\u001b[0m\n",
      "Epoch Started:51\n",
      "Epoch:51 |Train Loss:0.024076418264916067|Valid Loss:0.017963738832622766\n",
      "\u001b[35mTime taken by epoch 51 is 1.03s\u001b[0m\n",
      "Epoch Started:52\n",
      "Epoch:52 |Train Loss:0.014642531125757256|Valid Loss:0.011711426032707094\n",
      "\u001b[32mLoss Decreased from 0.012062108842656016 to 0.011711426032707094\u001b[0m\n",
      "\u001b[35mTime taken by epoch 52 is 1.58s\u001b[0m\n",
      "Epoch Started:53\n",
      "Epoch:53 |Train Loss:0.01280442848311443|Valid Loss:0.008927043247967958\n",
      "\u001b[32mLoss Decreased from 0.011711426032707094 to 0.008927043247967958\u001b[0m\n",
      "\u001b[35mTime taken by epoch 53 is 1.58s\u001b[0m\n",
      "Epoch Started:54\n",
      "Epoch:54 |Train Loss:0.011479407463124707|Valid Loss:0.0107197021599859\n",
      "\u001b[35mTime taken by epoch 54 is 1.01s\u001b[0m\n",
      "Epoch Started:55\n",
      "Epoch:55 |Train Loss:0.010570942240424062|Valid Loss:0.011656065005809069\n",
      "\u001b[35mTime taken by epoch 55 is 1.10s\u001b[0m\n",
      "Epoch Started:56\n",
      "Epoch:56 |Train Loss:0.011441983294820315|Valid Loss:0.008943495014682412\n",
      "\u001b[35mTime taken by epoch 56 is 1.03s\u001b[0m\n",
      "Epoch Started:57\n",
      "Epoch:57 |Train Loss:0.010364436568986429|Valid Loss:0.012579439021646977\n",
      "\u001b[35mTime taken by epoch 57 is 1.02s\u001b[0m\n",
      "Epoch Started:58\n",
      "Epoch:58 |Train Loss:0.011317923542504249|Valid Loss:0.008756139641627669\n",
      "\u001b[32mLoss Decreased from 0.008927043247967958 to 0.008756139641627669\u001b[0m\n",
      "\u001b[35mTime taken by epoch 58 is 1.54s\u001b[0m\n",
      "Epoch Started:59\n",
      "Epoch:59 |Train Loss:0.012431793012901357|Valid Loss:0.009457428473979235\n",
      "\u001b[35mTime taken by epoch 59 is 1.09s\u001b[0m\n",
      "Epoch Started:60\n",
      "Epoch:60 |Train Loss:0.010791876218526772|Valid Loss:0.01123666954226792\n",
      "\u001b[35mTime taken by epoch 60 is 1.00s\u001b[0m\n",
      "Epoch Started:61\n",
      "Epoch:61 |Train Loss:0.009956656060622711|Valid Loss:0.008356357412412762\n",
      "\u001b[32mLoss Decreased from 0.008756139641627669 to 0.008356357412412762\u001b[0m\n",
      "\u001b[35mTime taken by epoch 61 is 1.64s\u001b[0m\n",
      "Epoch Started:62\n",
      "Epoch:62 |Train Loss:0.013801231637204947|Valid Loss:0.012941479310393333\n",
      "\u001b[35mTime taken by epoch 62 is 1.07s\u001b[0m\n",
      "Epoch Started:63\n",
      "Epoch:63 |Train Loss:0.013177361118754274|Valid Loss:0.011512837419286371\n",
      "\u001b[35mTime taken by epoch 63 is 1.09s\u001b[0m\n",
      "Epoch Started:64\n",
      "Epoch:64 |Train Loss:0.01195110206639296|Valid Loss:0.012121093040332199\n",
      "\u001b[35mTime taken by epoch 64 is 1.11s\u001b[0m\n",
      "Epoch Started:65\n",
      "Epoch:65 |Train Loss:0.010755217989514532|Valid Loss:0.008697354840114713\n",
      "\u001b[35mTime taken by epoch 65 is 1.06s\u001b[0m\n",
      "Epoch Started:66\n",
      "Epoch:66 |Train Loss:0.009248715188158186|Valid Loss:0.008014967758208513\n",
      "\u001b[32mLoss Decreased from 0.008356357412412762 to 0.008014967758208513\u001b[0m\n",
      "\u001b[35mTime taken by epoch 66 is 1.62s\u001b[0m\n",
      "Epoch Started:67\n",
      "Epoch:67 |Train Loss:0.009043015000459394|Valid Loss:0.0096672466956079\n",
      "\u001b[35mTime taken by epoch 67 is 1.08s\u001b[0m\n",
      "Epoch Started:68\n",
      "Epoch:68 |Train Loss:0.0097382879129758|Valid Loss:0.008387750084511935\n",
      "\u001b[35mTime taken by epoch 68 is 1.06s\u001b[0m\n",
      "Epoch Started:69\n",
      "Epoch:69 |Train Loss:0.008983079895475194|Valid Loss:0.00904119061306119\n",
      "\u001b[35mTime taken by epoch 69 is 1.11s\u001b[0m\n",
      "Epoch Started:70\n",
      "Epoch:70 |Train Loss:0.009154300891647213|Valid Loss:0.009780868887901306\n",
      "\u001b[35mTime taken by epoch 70 is 1.01s\u001b[0m\n",
      "Epoch Started:71\n",
      "Epoch:71 |Train Loss:0.009469057739663281|Valid Loss:0.008577248780056834\n",
      "\u001b[35mTime taken by epoch 71 is 1.12s\u001b[0m\n",
      "Epoch Started:72\n",
      "Epoch:72 |Train Loss:0.008939036376480209|Valid Loss:0.010968777956441045\n",
      "\u001b[35mTime taken by epoch 72 is 1.10s\u001b[0m\n",
      "Epoch Started:73\n",
      "Epoch:73 |Train Loss:0.011932759766319865|Valid Loss:0.011707512103021145\n",
      "\u001b[35mTime taken by epoch 73 is 1.07s\u001b[0m\n",
      "Epoch Started:74\n",
      "Epoch:74 |Train Loss:0.009047030581553516|Valid Loss:0.007865176047198474\n",
      "\u001b[32mLoss Decreased from 0.008014967758208513 to 0.007865176047198474\u001b[0m\n",
      "\u001b[35mTime taken by epoch 74 is 1.56s\u001b[0m\n",
      "Epoch Started:75\n",
      "Epoch:75 |Train Loss:0.009026438169377414|Valid Loss:0.008215873362496495\n",
      "\u001b[35mTime taken by epoch 75 is 1.15s\u001b[0m\n",
      "Epoch Started:76\n",
      "Epoch:76 |Train Loss:0.008884216842584704|Valid Loss:0.011152419447898864\n",
      "\u001b[35mTime taken by epoch 76 is 1.03s\u001b[0m\n",
      "Epoch Started:77\n",
      "Epoch:77 |Train Loss:0.00837048406614677|Valid Loss:0.008594197081401944\n",
      "\u001b[35mTime taken by epoch 77 is 1.08s\u001b[0m\n",
      "Epoch Started:78\n",
      "Epoch:78 |Train Loss:0.0078836269309058|Valid Loss:0.008008404541760683\n",
      "\u001b[35mTime taken by epoch 78 is 1.13s\u001b[0m\n",
      "Epoch Started:79\n",
      "Epoch:79 |Train Loss:0.008048358066987834|Valid Loss:0.008624160010367633\n",
      "\u001b[35mTime taken by epoch 79 is 1.19s\u001b[0m\n",
      "Epoch Started:80\n",
      "Epoch:80 |Train Loss:0.008211407062940691|Valid Loss:0.00825237985700369\n",
      "\u001b[35mTime taken by epoch 80 is 1.05s\u001b[0m\n",
      "Epoch Started:81\n",
      "Epoch:81 |Train Loss:0.008111541600603806|Valid Loss:0.007946395315229893\n",
      "\u001b[35mTime taken by epoch 81 is 1.09s\u001b[0m\n",
      "Epoch Started:82\n",
      "Epoch:82 |Train Loss:0.007899855913006161|Valid Loss:0.008027131017297507\n",
      "\u001b[35mTime taken by epoch 82 is 1.07s\u001b[0m\n",
      "Epoch Started:83\n",
      "Epoch:83 |Train Loss:0.00785159864953082|Valid Loss:0.008720442187041044\n",
      "\u001b[35mTime taken by epoch 83 is 1.13s\u001b[0m\n",
      "Epoch Started:84\n",
      "Epoch:84 |Train Loss:0.008641602091589257|Valid Loss:0.009033949300646781\n",
      "\u001b[35mTime taken by epoch 84 is 1.13s\u001b[0m\n",
      "Epoch Started:85\n",
      "Epoch:85 |Train Loss:0.008534034248441458|Valid Loss:0.008509754296392202\n",
      "\u001b[35mTime taken by epoch 85 is 1.13s\u001b[0m\n",
      "Epoch Started:86\n",
      "Epoch:86 |Train Loss:0.009283386955135748|Valid Loss:0.00827309233136475\n",
      "\u001b[35mTime taken by epoch 86 is 1.12s\u001b[0m\n",
      "Epoch Started:87\n",
      "Epoch:87 |Train Loss:0.00780522828235438|Valid Loss:0.008433412108570338\n",
      "\u001b[35mTime taken by epoch 87 is 1.09s\u001b[0m\n",
      "Epoch Started:88\n",
      "Epoch:88 |Train Loss:0.008140407122769639|Valid Loss:0.008022133400663734\n",
      "\u001b[35mTime taken by epoch 88 is 1.07s\u001b[0m\n",
      "Epoch Started:89\n",
      "Epoch:89 |Train Loss:0.007719309498114805|Valid Loss:0.010411577299237251\n",
      "\u001b[35mTime taken by epoch 89 is 1.10s\u001b[0m\n",
      "Epoch Started:90\n",
      "Epoch:90 |Train Loss:0.008305844703787252|Valid Loss:0.008291885210201144\n",
      "\u001b[35mTime taken by epoch 90 is 1.12s\u001b[0m\n",
      "Epoch Started:91\n",
      "Epoch:91 |Train Loss:0.010029475302680543|Valid Loss:0.011101556429639458\n",
      "\u001b[35mTime taken by epoch 91 is 1.08s\u001b[0m\n",
      "Epoch Started:92\n",
      "Epoch:92 |Train Loss:0.0171737234157167|Valid Loss:0.03448468539863825\n",
      "\u001b[35mTime taken by epoch 92 is 1.09s\u001b[0m\n",
      "Epoch Started:93\n",
      "Epoch:93 |Train Loss:0.012601647293195128|Valid Loss:0.011851412244141102\n",
      "\u001b[35mTime taken by epoch 93 is 1.01s\u001b[0m\n",
      "Epoch Started:94\n",
      "Epoch:94 |Train Loss:0.008859295912675168|Valid Loss:0.00930008185096085\n",
      "\u001b[35mTime taken by epoch 94 is 1.01s\u001b[0m\n",
      "Epoch Started:95\n",
      "Epoch:95 |Train Loss:0.008066693725260464|Valid Loss:0.009760214574635028\n",
      "\u001b[35mTime taken by epoch 95 is 1.18s\u001b[0m\n",
      "Epoch Started:96\n",
      "Epoch:96 |Train Loss:0.009057584059375682|Valid Loss:0.008795520849525928\n",
      "\u001b[35mTime taken by epoch 96 is 1.04s\u001b[0m\n",
      "Epoch Started:97\n",
      "Epoch:97 |Train Loss:0.008673998257635455|Valid Loss:0.008419419312849641\n",
      "\u001b[35mTime taken by epoch 97 is 1.03s\u001b[0m\n",
      "Epoch Started:98\n",
      "Epoch:98 |Train Loss:0.00710218888707459|Valid Loss:0.008498092321678996\n",
      "\u001b[35mTime taken by epoch 98 is 1.06s\u001b[0m\n",
      "Epoch Started:99\n",
      "Epoch:99 |Train Loss:0.007470390367272653|Valid Loss:0.007846774253994226\n",
      "\u001b[32mLoss Decreased from 0.007865176047198474 to 0.007846774253994226\u001b[0m\n",
      "\u001b[35mTime taken by epoch 99 is 1.69s\u001b[0m\n",
      "Epoch Started:100\n",
      "Epoch:100 |Train Loss:0.007566783859051372|Valid Loss:0.008141153072938324\n",
      "\u001b[35mTime taken by epoch 100 is 1.07s\u001b[0m\n",
      "Epoch Started:101\n",
      "Epoch:101 |Train Loss:0.008094574974261616|Valid Loss:0.009160186816006898\n",
      "\u001b[35mTime taken by epoch 101 is 1.12s\u001b[0m\n",
      "Epoch Started:102\n",
      "Epoch:102 |Train Loss:0.007907678765293798|Valid Loss:0.011273477924987674\n",
      "\u001b[35mTime taken by epoch 102 is 1.10s\u001b[0m\n",
      "Epoch Started:103\n",
      "Epoch:103 |Train Loss:0.0075422997071750856|Valid Loss:0.008568803966045379\n",
      "\u001b[35mTime taken by epoch 103 is 1.02s\u001b[0m\n",
      "Epoch Started:104\n",
      "Epoch:104 |Train Loss:0.007986117534241393|Valid Loss:0.009183363849297166\n",
      "\u001b[35mTime taken by epoch 104 is 1.10s\u001b[0m\n",
      "Epoch Started:105\n",
      "Epoch:105 |Train Loss:0.007501544210275537|Valid Loss:0.008982164226472378\n",
      "\u001b[35mTime taken by epoch 105 is 1.20s\u001b[0m\n",
      "Epoch Started:106\n",
      "Epoch:106 |Train Loss:0.007548013260882152|Valid Loss:0.008532821875996887\n",
      "\u001b[35mTime taken by epoch 106 is 1.09s\u001b[0m\n",
      "Epoch Started:107\n",
      "Epoch:107 |Train Loss:0.007513960247467223|Valid Loss:0.008104553120210767\n",
      "\u001b[35mTime taken by epoch 107 is 1.08s\u001b[0m\n",
      "Epoch Started:108\n",
      "Epoch:108 |Train Loss:0.007547177521413879|Valid Loss:0.008077259548008442\n",
      "\u001b[35mTime taken by epoch 108 is 1.13s\u001b[0m\n",
      "Epoch Started:109\n",
      "Epoch:109 |Train Loss:0.0073196437503946455|Valid Loss:0.008540811762213708\n",
      "\u001b[35mTime taken by epoch 109 is 1.11s\u001b[0m\n",
      "Epoch Started:110\n",
      "Epoch:110 |Train Loss:0.007811705361267454|Valid Loss:0.008029274782165885\n",
      "\u001b[35mTime taken by epoch 110 is 1.11s\u001b[0m\n",
      "Epoch Started:111\n",
      "Epoch:111 |Train Loss:0.007021950165692128|Valid Loss:0.007788847992196679\n",
      "\u001b[32mLoss Decreased from 0.007846774253994226 to 0.007788847992196679\u001b[0m\n",
      "\u001b[35mTime taken by epoch 111 is 1.65s\u001b[0m\n",
      "Epoch Started:112\n",
      "Epoch:112 |Train Loss:0.00708582208148743|Valid Loss:0.007762074377387762\n",
      "\u001b[32mLoss Decreased from 0.007788847992196679 to 0.007762074377387762\u001b[0m\n",
      "\u001b[35mTime taken by epoch 112 is 1.54s\u001b[0m\n",
      "Epoch Started:113\n",
      "Epoch:113 |Train Loss:0.006700494853583605|Valid Loss:0.007635814463719725\n",
      "\u001b[32mLoss Decreased from 0.007762074377387762 to 0.007635814463719725\u001b[0m\n",
      "\u001b[35mTime taken by epoch 113 is 1.60s\u001b[0m\n",
      "Epoch Started:114\n",
      "Epoch:114 |Train Loss:0.007607026062415619|Valid Loss:0.00872099557891488\n",
      "\u001b[35mTime taken by epoch 114 is 1.20s\u001b[0m\n",
      "Epoch Started:115\n",
      "Epoch:115 |Train Loss:0.007332406215075599|Valid Loss:0.008964842651039362\n",
      "\u001b[35mTime taken by epoch 115 is 1.17s\u001b[0m\n",
      "Epoch Started:116\n",
      "Epoch:116 |Train Loss:0.007389591810734649|Valid Loss:0.008235489903017878\n",
      "\u001b[35mTime taken by epoch 116 is 1.19s\u001b[0m\n",
      "Epoch Started:117\n",
      "Epoch:117 |Train Loss:0.007147239815247686|Valid Loss:0.008566539036110044\n",
      "\u001b[35mTime taken by epoch 117 is 1.36s\u001b[0m\n",
      "Epoch Started:118\n",
      "Epoch:118 |Train Loss:0.006663155300836814|Valid Loss:0.007470683543942869\n",
      "\u001b[32mLoss Decreased from 0.007635814463719725 to 0.007470683543942869\u001b[0m\n",
      "\u001b[35mTime taken by epoch 118 is 1.96s\u001b[0m\n",
      "Epoch Started:119\n",
      "Epoch:119 |Train Loss:0.006867015195128165|Valid Loss:0.008098749769851565\n",
      "\u001b[35mTime taken by epoch 119 is 1.13s\u001b[0m\n",
      "Epoch Started:120\n",
      "Epoch:120 |Train Loss:0.00659177255032486|Valid Loss:0.009058179520070552\n",
      "\u001b[35mTime taken by epoch 120 is 1.03s\u001b[0m\n",
      "Epoch Started:121\n",
      "Epoch:121 |Train Loss:0.006841730571498996|Valid Loss:0.00739844252821058\n",
      "\u001b[32mLoss Decreased from 0.007470683543942869 to 0.00739844252821058\u001b[0m\n",
      "\u001b[35mTime taken by epoch 121 is 1.58s\u001b[0m\n",
      "Epoch Started:122\n",
      "Epoch:122 |Train Loss:0.00686008210514525|Valid Loss:0.00785271506756544\n",
      "\u001b[35mTime taken by epoch 122 is 1.12s\u001b[0m\n",
      "Epoch Started:123\n",
      "Epoch:123 |Train Loss:0.0065477931087738585|Valid Loss:0.008765213564038277\n",
      "\u001b[35mTime taken by epoch 123 is 1.05s\u001b[0m\n",
      "Epoch Started:124\n",
      "Epoch:124 |Train Loss:0.0064079355276925|Valid Loss:0.007850498426705599\n",
      "\u001b[35mTime taken by epoch 124 is 1.51s\u001b[0m\n",
      "Epoch Started:125\n",
      "Epoch:125 |Train Loss:0.006583305149290122|Valid Loss:0.007689525932073593\n",
      "\u001b[35mTime taken by epoch 125 is 1.07s\u001b[0m\n",
      "Epoch Started:126\n",
      "Epoch:126 |Train Loss:0.007024141579964443|Valid Loss:0.008720074733719229\n",
      "\u001b[35mTime taken by epoch 126 is 1.17s\u001b[0m\n",
      "Epoch Started:127\n",
      "Epoch:127 |Train Loss:0.00850856481855245|Valid Loss:0.013389189122244715\n",
      "\u001b[35mTime taken by epoch 127 is 1.09s\u001b[0m\n",
      "Epoch Started:128\n",
      "Epoch:128 |Train Loss:0.011749087146630413|Valid Loss:0.012521213479340076\n",
      "\u001b[35mTime taken by epoch 128 is 1.03s\u001b[0m\n",
      "Epoch Started:129\n",
      "Epoch:129 |Train Loss:0.007747386177805693|Valid Loss:0.008199500851333141\n",
      "\u001b[35mTime taken by epoch 129 is 1.06s\u001b[0m\n",
      "Epoch Started:130\n",
      "Epoch:130 |Train Loss:0.007554472497615375|Valid Loss:0.008025443926453591\n",
      "\u001b[35mTime taken by epoch 130 is 1.02s\u001b[0m\n",
      "Epoch Started:131\n",
      "Epoch:131 |Train Loss:0.006540564709882203|Valid Loss:0.008419649442657828\n",
      "\u001b[35mTime taken by epoch 131 is 1.16s\u001b[0m\n",
      "Epoch Started:132\n",
      "Epoch:132 |Train Loss:0.0064984598920043365|Valid Loss:0.008054428128525614\n",
      "\u001b[35mTime taken by epoch 132 is 1.07s\u001b[0m\n",
      "Epoch Started:133\n",
      "Epoch:133 |Train Loss:0.007461460932206951|Valid Loss:0.007809225469827652\n",
      "\u001b[35mTime taken by epoch 133 is 1.07s\u001b[0m\n",
      "Epoch Started:134\n",
      "Epoch:134 |Train Loss:0.007217009784653783|Valid Loss:0.009071837551891804\n",
      "\u001b[35mTime taken by epoch 134 is 1.05s\u001b[0m\n",
      "Epoch Started:135\n",
      "Epoch:135 |Train Loss:0.008294333667053204|Valid Loss:0.008341466123238207\n",
      "\u001b[35mTime taken by epoch 135 is 1.06s\u001b[0m\n",
      "Epoch Started:136\n",
      "Epoch:136 |Train Loss:0.007876786207290072|Valid Loss:0.00838486710563302\n",
      "\u001b[35mTime taken by epoch 136 is 1.08s\u001b[0m\n",
      "Epoch Started:137\n",
      "Epoch:137 |Train Loss:0.00787312738401325|Valid Loss:0.00799989108927548\n",
      "\u001b[35mTime taken by epoch 137 is 1.07s\u001b[0m\n",
      "Epoch Started:138\n",
      "Epoch:138 |Train Loss:0.006470612789455213|Valid Loss:0.007827927451580763\n",
      "\u001b[35mTime taken by epoch 138 is 1.06s\u001b[0m\n",
      "Epoch Started:139\n",
      "Epoch:139 |Train Loss:0.006335704011450473|Valid Loss:0.008145190076902509\n",
      "\u001b[35mTime taken by epoch 139 is 1.08s\u001b[0m\n",
      "Epoch Started:140\n",
      "Epoch:140 |Train Loss:0.006382311921027538|Valid Loss:0.01102289892733097\n",
      "\u001b[35mTime taken by epoch 140 is 1.12s\u001b[0m\n",
      "Epoch Started:141\n",
      "Epoch:141 |Train Loss:0.00674010753190439|Valid Loss:0.008016715943813323\n",
      "\u001b[35mTime taken by epoch 141 is 1.01s\u001b[0m\n",
      "Epoch Started:142\n",
      "Epoch:142 |Train Loss:0.006539699535718874|Valid Loss:0.007793588237836957\n",
      "\u001b[35mTime taken by epoch 142 is 1.06s\u001b[0m\n",
      "Epoch Started:143\n",
      "Epoch:143 |Train Loss:0.006480075492474593|Valid Loss:0.008373626600950956\n",
      "\u001b[35mTime taken by epoch 143 is 1.03s\u001b[0m\n",
      "Epoch Started:144\n",
      "Epoch:144 |Train Loss:0.006420218238705083|Valid Loss:0.008182224398478866\n",
      "\u001b[35mTime taken by epoch 144 is 1.04s\u001b[0m\n",
      "Epoch Started:145\n",
      "Epoch:145 |Train Loss:0.0064936581950046516|Valid Loss:0.007904979772865773\n",
      "\u001b[35mTime taken by epoch 145 is 0.99s\u001b[0m\n",
      "Epoch Started:146\n",
      "Epoch:146 |Train Loss:0.0065504713719220535|Valid Loss:0.008109433646313845\n",
      "\u001b[35mTime taken by epoch 146 is 1.01s\u001b[0m\n",
      "Epoch Started:147\n",
      "Epoch:147 |Train Loss:0.00593408398746856|Valid Loss:0.007995950360782444\n",
      "\u001b[35mTime taken by epoch 147 is 0.99s\u001b[0m\n",
      "Epoch Started:148\n",
      "Epoch:148 |Train Loss:0.006355714347017438|Valid Loss:0.007851975434459747\n",
      "\u001b[35mTime taken by epoch 148 is 1.06s\u001b[0m\n",
      "Epoch Started:149\n",
      "Epoch:149 |Train Loss:0.006133256241140005|Valid Loss:0.007835434190928936\n",
      "\u001b[35mTime taken by epoch 149 is 1.02s\u001b[0m\n",
      "Epoch Started:150\n",
      "Epoch:150 |Train Loss:0.006497680491424705|Valid Loss:0.008005405310541391\n",
      "\u001b[35mTime taken by epoch 150 is 1.06s\u001b[0m\n",
      "Epoch Started:151\n",
      "Epoch:151 |Train Loss:0.006632270891905615|Valid Loss:0.00787452724762261\n",
      "\u001b[35mTime taken by epoch 151 is 1.00s\u001b[0m\n",
      "Epoch Started:152\n",
      "Epoch:152 |Train Loss:0.006179528813318987|Valid Loss:0.008572712354362012\n",
      "\u001b[35mTime taken by epoch 152 is 1.03s\u001b[0m\n",
      "Epoch Started:153\n",
      "Epoch:153 |Train Loss:0.0063519699094620975|Valid Loss:0.008479520212858915\n",
      "\u001b[35mTime taken by epoch 153 is 1.05s\u001b[0m\n",
      "Epoch Started:154\n",
      "Epoch:154 |Train Loss:0.005914080189540982|Valid Loss:0.00782495595049113\n",
      "\u001b[35mTime taken by epoch 154 is 1.11s\u001b[0m\n",
      "Epoch Started:155\n",
      "Epoch:155 |Train Loss:0.006283577004643648|Valid Loss:0.007845381461083888\n",
      "\u001b[35mTime taken by epoch 155 is 1.06s\u001b[0m\n",
      "Epoch Started:156\n",
      "Epoch:156 |Train Loss:0.006090410592916764|Valid Loss:0.008665171964094043\n",
      "\u001b[35mTime taken by epoch 156 is 1.13s\u001b[0m\n",
      "Epoch Started:157\n",
      "Epoch:157 |Train Loss:0.006257898345785706|Valid Loss:0.00838253037072718\n",
      "\u001b[35mTime taken by epoch 157 is 1.19s\u001b[0m\n",
      "Epoch Started:158\n",
      "Epoch:158 |Train Loss:0.006558341354033665|Valid Loss:0.007849457254633308\n",
      "\u001b[35mTime taken by epoch 158 is 1.16s\u001b[0m\n",
      "Epoch Started:159\n",
      "Epoch:159 |Train Loss:0.006010019054979478|Valid Loss:0.008165565086528659\n",
      "\u001b[35mTime taken by epoch 159 is 1.02s\u001b[0m\n",
      "Epoch Started:160\n",
      "Epoch:160 |Train Loss:0.005926040540400304|Valid Loss:0.007868463732302189\n",
      "\u001b[35mTime taken by epoch 160 is 1.05s\u001b[0m\n",
      "Epoch Started:161\n",
      "Epoch:161 |Train Loss:0.005846895920847983|Valid Loss:0.01114438457880169\n",
      "\u001b[35mTime taken by epoch 161 is 1.17s\u001b[0m\n",
      "Epoch Started:162\n",
      "Epoch:162 |Train Loss:0.005968926541850363|Valid Loss:0.008166491147130727\n",
      "\u001b[35mTime taken by epoch 162 is 1.01s\u001b[0m\n",
      "Epoch Started:163\n",
      "Epoch:163 |Train Loss:0.005682716483103209|Valid Loss:0.007926147989928722\n",
      "\u001b[35mTime taken by epoch 163 is 1.04s\u001b[0m\n",
      "Epoch Started:164\n",
      "Epoch:164 |Train Loss:0.006016824523134059|Valid Loss:0.008297546370886266\n",
      "\u001b[35mTime taken by epoch 164 is 1.08s\u001b[0m\n",
      "Epoch Started:165\n",
      "Epoch:165 |Train Loss:0.006057571993503524|Valid Loss:0.008704577968455852\n",
      "\u001b[35mTime taken by epoch 165 is 1.15s\u001b[0m\n",
      "Epoch Started:166\n",
      "Epoch:166 |Train Loss:0.006161744479629162|Valid Loss:0.008036764711141587\n",
      "\u001b[35mTime taken by epoch 166 is 1.12s\u001b[0m\n",
      "Epoch Started:167\n",
      "Epoch:167 |Train Loss:0.006022219895385206|Valid Loss:0.008558692969381809\n",
      "\u001b[35mTime taken by epoch 167 is 1.41s\u001b[0m\n",
      "Epoch Started:168\n",
      "Epoch:168 |Train Loss:0.006248093786110219|Valid Loss:0.008654915960505605\n",
      "\u001b[35mTime taken by epoch 168 is 1.15s\u001b[0m\n",
      "Epoch Started:169\n",
      "Epoch:169 |Train Loss:0.0061445034256106925|Valid Loss:0.009914009924978017\n",
      "\u001b[35mTime taken by epoch 169 is 1.20s\u001b[0m\n",
      "Epoch Started:170\n",
      "Epoch:170 |Train Loss:0.005984547057826268|Valid Loss:0.008093980024568737\n",
      "\u001b[35mTime taken by epoch 170 is 1.13s\u001b[0m\n",
      "Epoch Started:171\n",
      "Epoch:171 |Train Loss:0.005929313379486925|Valid Loss:0.008424644288606942\n",
      "\u001b[35mTime taken by epoch 171 is 1.07s\u001b[0m\n",
      "Epoch Started:172\n",
      "Epoch:172 |Train Loss:0.006032199267984221|Valid Loss:0.00792618349660188\n",
      "\u001b[35mTime taken by epoch 172 is 1.13s\u001b[0m\n",
      "Epoch Started:173\n",
      "Epoch:173 |Train Loss:0.0060434429048511545|Valid Loss:0.008962568454444408\n",
      "\u001b[35mTime taken by epoch 173 is 1.03s\u001b[0m\n",
      "Epoch Started:174\n",
      "Epoch:174 |Train Loss:0.0057801413165993595|Valid Loss:0.008113570045679808\n",
      "\u001b[35mTime taken by epoch 174 is 1.17s\u001b[0m\n",
      "Epoch Started:175\n",
      "Epoch:175 |Train Loss:0.00612416141666472|Valid Loss:0.00840543385129422\n",
      "\u001b[35mTime taken by epoch 175 is 1.15s\u001b[0m\n",
      "Epoch Started:176\n",
      "Epoch:176 |Train Loss:0.006350160956284718|Valid Loss:0.007858840888366104\n",
      "\u001b[35mTime taken by epoch 176 is 1.08s\u001b[0m\n",
      "Epoch Started:177\n",
      "Epoch:177 |Train Loss:0.01589801315659363|Valid Loss:0.03160130400210619\n",
      "\u001b[35mTime taken by epoch 177 is 1.00s\u001b[0m\n",
      "Epoch Started:178\n",
      "Epoch:178 |Train Loss:0.023335161300278025|Valid Loss:0.03321394333615899\n",
      "\u001b[35mTime taken by epoch 178 is 1.09s\u001b[0m\n",
      "Epoch Started:179\n",
      "Epoch:179 |Train Loss:0.022552023666273607|Valid Loss:0.03407511953264475\n",
      "\u001b[35mTime taken by epoch 179 is 1.06s\u001b[0m\n",
      "Epoch Started:180\n",
      "Epoch:180 |Train Loss:0.017195883231531633|Valid Loss:0.028145953454077242\n",
      "\u001b[35mTime taken by epoch 180 is 1.06s\u001b[0m\n",
      "Epoch Started:181\n",
      "Epoch:181 |Train Loss:0.026066268573662166|Valid Loss:0.02697215471416712\n",
      "\u001b[35mTime taken by epoch 181 is 1.04s\u001b[0m\n",
      "Epoch Started:182\n",
      "Epoch:182 |Train Loss:0.02261216284118985|Valid Loss:0.02139697428792715\n",
      "\u001b[35mTime taken by epoch 182 is 1.08s\u001b[0m\n",
      "Epoch Started:183\n",
      "Epoch:183 |Train Loss:0.023503267059200687|Valid Loss:0.028410095255821943\n",
      "\u001b[35mTime taken by epoch 183 is 1.05s\u001b[0m\n",
      "Epoch Started:184\n",
      "Epoch:184 |Train Loss:0.023594189288192673|Valid Loss:0.03227394167333841\n",
      "\u001b[35mTime taken by epoch 184 is 1.04s\u001b[0m\n",
      "Epoch Started:185\n",
      "Epoch:185 |Train Loss:0.0239655175981553|Valid Loss:0.027927490323781966\n",
      "\u001b[35mTime taken by epoch 185 is 1.24s\u001b[0m\n",
      "Epoch Started:186\n",
      "Epoch:186 |Train Loss:0.02423584404842634|Valid Loss:0.027848886139690877\n",
      "\u001b[35mTime taken by epoch 186 is 1.12s\u001b[0m\n",
      "Epoch Started:187\n",
      "Epoch:187 |Train Loss:0.023316041492906055|Valid Loss:0.025745700113475323\n",
      "\u001b[35mTime taken by epoch 187 is 1.08s\u001b[0m\n",
      "Epoch Started:188\n",
      "Epoch:188 |Train Loss:0.02184189008058686|Valid Loss:0.018128758855164052\n",
      "\u001b[35mTime taken by epoch 188 is 1.38s\u001b[0m\n",
      "Epoch Started:189\n",
      "Epoch:189 |Train Loss:0.015845382610630048|Valid Loss:0.017378766695037483\n",
      "\u001b[35mTime taken by epoch 189 is 1.22s\u001b[0m\n",
      "Epoch Started:190\n",
      "Epoch:190 |Train Loss:0.018647848800020784|Valid Loss:0.020504451310262083\n",
      "\u001b[35mTime taken by epoch 190 is 1.13s\u001b[0m\n",
      "Epoch Started:191\n",
      "Epoch:191 |Train Loss:0.01515809815426014|Valid Loss:0.01156833185814321\n",
      "\u001b[35mTime taken by epoch 191 is 1.01s\u001b[0m\n",
      "Epoch Started:192\n",
      "Epoch:192 |Train Loss:0.01196668902412057|Valid Loss:0.011652746051549912\n",
      "\u001b[35mTime taken by epoch 192 is 1.38s\u001b[0m\n",
      "Epoch Started:193\n",
      "Epoch:193 |Train Loss:0.008369020235381629|Valid Loss:0.010120691126212477\n",
      "\u001b[35mTime taken by epoch 193 is 1.08s\u001b[0m\n",
      "Epoch Started:194\n",
      "Epoch:194 |Train Loss:0.009168655562557672|Valid Loss:0.012349749589338899\n",
      "\u001b[35mTime taken by epoch 194 is 1.06s\u001b[0m\n",
      "Epoch Started:195\n",
      "Epoch:195 |Train Loss:0.008039343746771154|Valid Loss:0.009765549935400486\n",
      "\u001b[35mTime taken by epoch 195 is 1.52s\u001b[0m\n",
      "Epoch Started:196\n",
      "Epoch:196 |Train Loss:0.007173867663368583|Valid Loss:0.009018841153010725\n",
      "\u001b[35mTime taken by epoch 196 is 1.11s\u001b[0m\n",
      "Epoch Started:197\n",
      "Epoch:197 |Train Loss:0.006752831003579654|Valid Loss:0.00906469076871872\n",
      "\u001b[35mTime taken by epoch 197 is 1.03s\u001b[0m\n",
      "Epoch Started:198\n",
      "Epoch:198 |Train Loss:0.007954582149211905|Valid Loss:0.011878200666978955\n",
      "\u001b[35mTime taken by epoch 198 is 1.02s\u001b[0m\n",
      "Epoch Started:199\n",
      "Epoch:199 |Train Loss:0.007610053890139649|Valid Loss:0.009096695389598609\n",
      "\u001b[35mTime taken by epoch 199 is 1.04s\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "best_loss, model = run(model,train_dl,val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
